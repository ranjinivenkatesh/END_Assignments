{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Opus100_Corpus_with_Attn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranjinivenkatesh/END_Assignments/blob/main/Assignment_9/Opus100_Corpus_with_Attn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBwNvWpYAqN-",
        "outputId": "1868e1b1-e037-4068-a10d-7b548fe53626"
      },
      "source": [
        "!wget http://data.statmt.org/opus-100-corpus/v1.0/supervised/en-es/opus.en-es-dev.en\r\n",
        "!wget http://data.statmt.org/opus-100-corpus/v1.0/supervised/en-es/opus.en-es-dev.es\r\n",
        "!wget http://data.statmt.org/opus-100-corpus/v1.0/supervised/en-es/opus.en-es-test.en\r\n",
        "!wget http://data.statmt.org/opus-100-corpus/v1.0/supervised/en-es/opus.en-es-test.es\r\n",
        "!wget http://data.statmt.org/opus-100-corpus/v1.0/supervised/en-es/opus.en-es-train.en\r\n",
        "!wget http://data.statmt.org/opus-100-corpus/v1.0/supervised/en-es/opus.en-es-train.es"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-30 12:34:39--  http://data.statmt.org/opus-100-corpus/v1.0/supervised/en-es/opus.en-es-dev.en\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149835 (146K)\n",
            "Saving to: ‘opus.en-es-dev.en’\n",
            "\n",
            "opus.en-es-dev.en   100%[===================>] 146.32K   187KB/s    in 0.8s    \n",
            "\n",
            "2020-12-30 12:34:41 (187 KB/s) - ‘opus.en-es-dev.en’ saved [149835/149835]\n",
            "\n",
            "--2020-12-30 12:34:41--  http://data.statmt.org/opus-100-corpus/v1.0/supervised/en-es/opus.en-es-dev.es\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 164892 (161K)\n",
            "Saving to: ‘opus.en-es-dev.es’\n",
            "\n",
            "opus.en-es-dev.es   100%[===================>] 161.03K   205KB/s    in 0.8s    \n",
            "\n",
            "2020-12-30 12:34:42 (205 KB/s) - ‘opus.en-es-dev.es’ saved [164892/164892]\n",
            "\n",
            "--2020-12-30 12:34:42--  http://data.statmt.org/opus-100-corpus/v1.0/supervised/en-es/opus.en-es-test.en\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 150105 (147K)\n",
            "Saving to: ‘opus.en-es-test.en’\n",
            "\n",
            "opus.en-es-test.en  100%[===================>] 146.59K   186KB/s    in 0.8s    \n",
            "\n",
            "2020-12-30 12:34:44 (186 KB/s) - ‘opus.en-es-test.en’ saved [150105/150105]\n",
            "\n",
            "--2020-12-30 12:34:44--  http://data.statmt.org/opus-100-corpus/v1.0/supervised/en-es/opus.en-es-test.es\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 164157 (160K)\n",
            "Saving to: ‘opus.en-es-test.es’\n",
            "\n",
            "opus.en-es-test.es  100%[===================>] 160.31K   207KB/s    in 0.8s    \n",
            "\n",
            "2020-12-30 12:34:45 (207 KB/s) - ‘opus.en-es-test.es’ saved [164157/164157]\n",
            "\n",
            "--2020-12-30 12:34:45--  http://data.statmt.org/opus-100-corpus/v1.0/supervised/en-es/opus.en-es-train.en\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 62730250 (60M)\n",
            "Saving to: ‘opus.en-es-train.en’\n",
            "\n",
            "opus.en-es-train.en 100%[===================>]  59.82M  11.1MB/s    in 7.0s    \n",
            "\n",
            "2020-12-30 12:34:53 (8.50 MB/s) - ‘opus.en-es-train.en’ saved [62730250/62730250]\n",
            "\n",
            "--2020-12-30 12:34:53--  http://data.statmt.org/opus-100-corpus/v1.0/supervised/en-es/opus.en-es-train.es\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 67912854 (65M)\n",
            "Saving to: ‘opus.en-es-train.es’\n",
            "\n",
            "opus.en-es-train.es 100%[===================>]  64.77M  11.4MB/s    in 7.4s    \n",
            "\n",
            "2020-12-30 12:35:01 (8.77 MB/s) - ‘opus.en-es-train.es’ saved [67912854/67912854]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYvILlbpBOj7",
        "outputId": "a66b67f3-8f7a-4e34-dbd4-5cf174374c8e"
      },
      "source": [
        "import pandas as pd\r\n",
        "train_en_df = pd.read_csv(\"opus.en-es-train.en\", header = None, sep=\"\\r\\n\", engine=\"python\")\r\n",
        "test_en_df = pd.read_csv(\"opus.en-es-test.en\", header = None, sep=\"\\r\\n\", engine=\"python\")\r\n",
        "valid_en_df = pd.read_csv(\"opus.en-es-dev.en\", header = None, sep=\"\\r\\n\", engine=\"python\")\r\n",
        "train_en_df, test_en_df, valid_en_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                                        0\n",
              " 0        It was the asbestos in here, that's what did it!\n",
              " 1                                        I'm out of here.\n",
              " 2        One time, I swear I pooped out a stick of chalk.\n",
              " 3                  And I will move, do you understand me?\n",
              " 4                                   - Thank you, my lord.\n",
              " ...                                                   ...\n",
              " 999995  He's not supposed to be here, so... there must...\n",
              " 999996                                     But Loreen is.\n",
              " 999997                                   Charles O'Brien?\n",
              " 999998                                It's... it's great.\n",
              " 999999  In contact with Priscilla Midori and Victor Ma...\n",
              " \n",
              " [1000000 rows x 1 columns],\n",
              "                                                       0\n",
              " 0     If your country produced ODS for this purpose,...\n",
              " 1     ♪ juvie the great man, who else could it be bu...\n",
              " 2                       The home planet is running out.\n",
              " 3                  Oon't girls ever kill their mothers?\n",
              " 4     Humanitarian, recovery and development activities\n",
              " ...                                                 ...\n",
              " 1995                      Megan! I need to talk to you.\n",
              " 1996  - Now that I have your attention, imagine we a...\n",
              " 1997  Do not be concerned, these tips may help you p...\n",
              " 1998                    She started slipping last year.\n",
              " 1999  For if many died through one man's falling awa...\n",
              " \n",
              " [2000 rows x 1 columns],\n",
              "                                                       0\n",
              " 0       I don't even remember what the fight was about.\n",
              " 1     Here are the sites of each of those that have ...\n",
              " 2                    I'm the man who killed Blackbeard.\n",
              " 3                                      Don't get smart.\n",
              " 4     Is there an exact moment in the life of a sold...\n",
              " ...                                                 ...\n",
              " 1995                [Scoffs] I believe the script says,\n",
              " 1996           You didn't even have a case against him.\n",
              " 1997                                    Ok. She's dead.\n",
              " 1998  Opinion of Advocate General Léger delivered on...\n",
              " 1999                               Prepare, yourselves.\n",
              " \n",
              " [2000 rows x 1 columns])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHgbVbl8BOhX",
        "outputId": "f9980cf4-c673-412e-8947-70aa7abd09b9"
      },
      "source": [
        "train_es_df = pd.read_csv(\"opus.en-es-train.es\", header = None, sep=\"\\r\\n\", engine=\"python\")\r\n",
        "test_es_df = pd.read_csv(\"opus.en-es-test.es\", header = None, sep=\"\\r\\n\", engine=\"python\")\r\n",
        "valid_es_df = pd.read_csv(\"opus.en-es-dev.es\", header = None, sep=\"\\r\\n\", engine=\"python\")\r\n",
        "train_es_df, test_es_df, valid_es_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                                        0\n",
              " 0       Fueron los asbestos aquí. ¡Eso es lo que ocurrió!\n",
              " 1                                         Me voy de aquí.\n",
              " 2              Una vez, juro que cagué una barra de tiza.\n",
              " 3                         Y prefiero mudarme, ¿Entiendes?\n",
              " 4                                              - Gracias.\n",
              " ...                                                   ...\n",
              " 999995  El no debería estar aquí, así que... Debe habe...\n",
              " 999996                                       Pero Loreen.\n",
              " 999997                                - ¿Charles O'Brien?\n",
              " 999998                                         Es genial.\n",
              " 999999  Priscilla Midori y Marcello Victor, los cerebr...\n",
              " \n",
              " [1000000 rows x 1 columns],\n",
              "                                                       0\n",
              " 0     Si su país produjo SAO para estos usos, sírvas...\n",
              " 1     # Juvie el gran hombre, ¿quién podría ser sino...\n",
              " 2                    El planeta madre se está agotando.\n",
              " 3                   Las chicas no matan a sus madres? .\n",
              " 4     Actividades humanitarias, de recuperación y de...\n",
              " ...                                                 ...\n",
              " 1995                    Megan, necesito hablar contigo.\n",
              " 1996  - Le veo interesado, añádale otro cero al precio.\n",
              " 1997  No se preocupe, estos consejos pueden ayudarle...\n",
              " 1998                       Empezó a irse el año pasado.\n",
              " 1999  15Mas no como el delito, tal fué el don: porqu...\n",
              " \n",
              " [2000 rows x 1 columns],\n",
              "                                                       0\n",
              " 0                     No recuerdo por qué fue la pelea.\n",
              " 1     Estos son los sitios en que cada Congreso ha t...\n",
              " 2              Sí. Soy el hombre que mató a Barbanegra.\n",
              " 3                           No te hagas el inteligente.\n",
              " 4     ¿Existe un límite de cuándo se padece y cuándo...\n",
              " ...                                                 ...\n",
              " 1995                       Me parece que el guión dice:\n",
              " 1996           Ni siquiera tenían un caso en su contra.\n",
              " 1997                            Como lo desees, cariño.\n",
              " 1998  Conclusiones del Abogado General Sr. P. Léger,...\n",
              " 1999                                        Preparense.\n",
              " \n",
              " [2000 rows x 1 columns])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tRVfL2hBOfG"
      },
      "source": [
        "train_df = pd.concat([train_en_df, train_es_df], axis=1)\r\n",
        "test_df = pd.concat([test_en_df, test_es_df], axis=1)\r\n",
        "valid_df = pd.concat([valid_en_df, valid_es_df], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3fAk-X3BOcS",
        "outputId": "ca0da0b3-2f4b-4274-e697-35c33ece6bc8"
      },
      "source": [
        "train_df.columns=[\"English\", \"Spanish\"]\r\n",
        "test_df.columns=[\"English\", \"Spanish\"]\r\n",
        "valid_df.columns=[\"English\", \"Spanish\"]\r\n",
        "train_df, test_df, valid_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                                  English                                            Spanish\n",
              " 0        It was the asbestos in here, that's what did it!  Fueron los asbestos aquí. ¡Eso es lo que ocurrió!\n",
              " 1                                        I'm out of here.                                    Me voy de aquí.\n",
              " 2        One time, I swear I pooped out a stick of chalk.         Una vez, juro que cagué una barra de tiza.\n",
              " 3                  And I will move, do you understand me?                    Y prefiero mudarme, ¿Entiendes?\n",
              " 4                                   - Thank you, my lord.                                         - Gracias.\n",
              " ...                                                   ...                                                ...\n",
              " 999995  He's not supposed to be here, so... there must...  El no debería estar aquí, así que... Debe habe...\n",
              " 999996                                     But Loreen is.                                       Pero Loreen.\n",
              " 999997                                   Charles O'Brien?                                - ¿Charles O'Brien?\n",
              " 999998                                It's... it's great.                                         Es genial.\n",
              " 999999  In contact with Priscilla Midori and Victor Ma...  Priscilla Midori y Marcello Victor, los cerebr...\n",
              " \n",
              " [1000000 rows x 2 columns],\n",
              "                                                 English                                            Spanish\n",
              " 0     If your country produced ODS for this purpose,...  Si su país produjo SAO para estos usos, sírvas...\n",
              " 1     ♪ juvie the great man, who else could it be bu...  # Juvie el gran hombre, ¿quién podría ser sino...\n",
              " 2                       The home planet is running out.                 El planeta madre se está agotando.\n",
              " 3                  Oon't girls ever kill their mothers?                Las chicas no matan a sus madres? .\n",
              " 4     Humanitarian, recovery and development activities  Actividades humanitarias, de recuperación y de...\n",
              " ...                                                 ...                                                ...\n",
              " 1995                      Megan! I need to talk to you.                    Megan, necesito hablar contigo.\n",
              " 1996  - Now that I have your attention, imagine we a...  - Le veo interesado, añádale otro cero al precio.\n",
              " 1997  Do not be concerned, these tips may help you p...  No se preocupe, estos consejos pueden ayudarle...\n",
              " 1998                    She started slipping last year.                       Empezó a irse el año pasado.\n",
              " 1999  For if many died through one man's falling awa...  15Mas no como el delito, tal fué el don: porqu...\n",
              " \n",
              " [2000 rows x 2 columns],\n",
              "                                                 English                                            Spanish\n",
              " 0       I don't even remember what the fight was about.                  No recuerdo por qué fue la pelea.\n",
              " 1     Here are the sites of each of those that have ...  Estos son los sitios en que cada Congreso ha t...\n",
              " 2                    I'm the man who killed Blackbeard.           Sí. Soy el hombre que mató a Barbanegra.\n",
              " 3                                      Don't get smart.                        No te hagas el inteligente.\n",
              " 4     Is there an exact moment in the life of a sold...  ¿Existe un límite de cuándo se padece y cuándo...\n",
              " ...                                                 ...                                                ...\n",
              " 1995                [Scoffs] I believe the script says,                       Me parece que el guión dice:\n",
              " 1996           You didn't even have a case against him.           Ni siquiera tenían un caso en su contra.\n",
              " 1997                                    Ok. She's dead.                            Como lo desees, cariño.\n",
              " 1998  Opinion of Advocate General Léger delivered on...  Conclusiones del Abogado General Sr. P. Léger,...\n",
              " 1999                               Prepare, yourselves.                                        Preparense.\n",
              " \n",
              " [2000 rows x 2 columns])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gOsuv01AwBZ",
        "outputId": "4c186cfd-4a01-4fc5-e46e-6243723a4446"
      },
      "source": [
        "df = train_df\r\n",
        "print(\"train before: \", len(df))\r\n",
        "df['English'] = df['English'].astype('str')\r\n",
        "mask = (df['English'].str.len() <= 40)\r\n",
        "df = df.loc[mask]\r\n",
        "print(\"train after: \", len(df))\r\n",
        "train_df = df\r\n",
        "\r\n",
        "df = test_df\r\n",
        "print(\"test before: \", len(df))\r\n",
        "df['English'] = df['English'].astype('str')\r\n",
        "mask = (df['English'].str.len() <= 40)\r\n",
        "df = df.loc[mask]\r\n",
        "print(\"test after: \", len(df))\r\n",
        "test_df = df\r\n",
        "\r\n",
        "df = valid_df\r\n",
        "print(\"valid before: \", len(df))\r\n",
        "df['English'] = df['English'].astype('str')\r\n",
        "mask = (df['English'].str.len() <= 40)\r\n",
        "df = df.loc[mask]\r\n",
        "print(\"valid after: \", len(df))\r\n",
        "valid_df = df\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train before:  1000000\n",
            "train after:  576303\n",
            "test before:  2000\n",
            "test after:  914\n",
            "valid before:  2000\n",
            "valid after:  943\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJTQi9WQ4-i0"
      },
      "source": [
        "# Import Library\r\n",
        "import random\r\n",
        "import torch, torchtext\r\n",
        "from torchtext import data \r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "from torchtext.data import Field, BucketIterator\r\n",
        "import spacy\r\n",
        "import numpy as np\r\n",
        "import math\r\n",
        "import time\r\n",
        "\r\n",
        "\r\n",
        "#Then set a random seed for deterministic results/reproducability.\r\n",
        "SEED = 1234\r\n",
        "random.seed(SEED)\r\n",
        "np.random.seed(SEED)\r\n",
        "torch.manual_seed(SEED)\r\n",
        "torch.cuda.manual_seed(SEED)\r\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDKTeXzNColv",
        "outputId": "53182aaf-2625-47bf-89ad-72201f63a2c0"
      },
      "source": [
        "!python -m spacy download en\r\n",
        "!python -m spacy download es"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (51.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting es_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.2.5/es_core_news_sm-2.2.5.tar.gz (16.2MB)\n",
            "\u001b[K     |████████████████████████████████| 16.2MB 1.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from es_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (51.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.19.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.4.0)\n",
            "Building wheels for collected packages: es-core-news-sm\n",
            "  Building wheel for es-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for es-core-news-sm: filename=es_core_news_sm-2.2.5-cp36-none-any.whl size=16172935 sha256=6eaa6dd7b48f776ec34db555f78fec1c7fa85670ffd47209eef3ea33f7c8443e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-42utl5a3/wheels/05/4f/66/9d0c806f86de08e8645d67996798c49e1512f9c3a250d74242\n",
            "Successfully built es-core-news-sm\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/es_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/es\n",
            "You can now load the model via spacy.load('es')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRvrH2I6-0Qt"
      },
      "source": [
        "spacy_es = spacy.load('es')\r\n",
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtSzi2RhC_qT"
      },
      "source": [
        "def tokenize_es(text):\r\n",
        "    \"\"\"\r\n",
        "    Tokenizes Spanish text from a string into a list of strings\r\n",
        "    \"\"\"\r\n",
        "    return [tok.text for tok in spacy_es.tokenizer(text)]\r\n",
        "\r\n",
        "def tokenize_en(text):\r\n",
        "    \"\"\"\r\n",
        "    Tokenizes English text from a string into a list of strings\r\n",
        "    \"\"\"\r\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlc6SF3_C_h8"
      },
      "source": [
        "SRC = torchtext.data.Field(tokenize=tokenize_en, \r\n",
        "            init_token='<sos>', \r\n",
        "            eos_token='<eos>', \r\n",
        "            lower=True)\r\n",
        "\r\n",
        "TRG = torchtext.data.Field(tokenize = tokenize_es, \r\n",
        "            init_token='<sos>', \r\n",
        "            eos_token='<eos>', \r\n",
        "            lower=True)\r\n",
        "\r\n",
        "fields = [('English', SRC), ('Spanish', TRG)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQrWSvPI4-V2"
      },
      "source": [
        "from torchtext import data\r\n",
        "\r\n",
        "class DataFrameDataset(data.Dataset):\r\n",
        "\r\n",
        "    def __init__(self, df, text_field, label_field, is_test=False, **kwargs):\r\n",
        "        fields = [('text', text_field), ('label', label_field)]\r\n",
        "        examples = []\r\n",
        "        for i, row in df.iterrows():\r\n",
        "            label = row.Spanish if not is_test else None\r\n",
        "            text = row.English\r\n",
        "            examples.append(data.Example.fromlist([text, label], fields))\r\n",
        "\r\n",
        "        super().__init__(examples, fields, **kwargs)\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def sort_key(ex):\r\n",
        "        return len(ex.text)\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def splits(cls, text_field, label_field, train_df, val_df=None, test_df=None, **kwargs):\r\n",
        "        train_data, val_data, test_data = (None, None, None)\r\n",
        "\r\n",
        "        if train_df is not None:\r\n",
        "            train_data = cls(train_df.copy(), text_field, label_field, **kwargs)\r\n",
        "        if val_df is not None:\r\n",
        "            val_data = cls(val_df.copy(), text_field, label_field, **kwargs)\r\n",
        "        if test_df is not None:\r\n",
        "            test_data = cls(test_df.copy(), text_field, label_field, True, **kwargs)\r\n",
        "\r\n",
        "        return tuple(d for d in (train_data, val_data, test_data) if d is not None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7VYyEtw4-QM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c434d168-2d5f-4168-95c6-1815aec29e68"
      },
      "source": [
        "train_df['English'] = train_df['English'].astype(str)\r\n",
        "train_df['Spanish'] = train_df['Spanish'].astype(str)\r\n",
        "valid_df['English'] = valid_df['English'].astype(str)\r\n",
        "valid_df['Spanish'] = valid_df['Spanish'].astype(str)\r\n",
        "test_df['English'] = test_df['English'].astype(str)\r\n",
        "test_df['Spanish'] = test_df['Spanish'].astype(str)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1NoGu4bY95v"
      },
      "source": [
        "train_example = [data.Example.fromlist([train_df.English.iloc[i],train_df.Spanish.iloc[i]], fields) for i in range(train_df.shape[0])]\r\n",
        "valid_example = [data.Example.fromlist([valid_df.English.iloc[i],valid_df.Spanish.iloc[i]], fields) for i in range(valid_df.shape[0])]\r\n",
        "test_example = [data.Example.fromlist([test_df.English.iloc[i],test_df.Spanish.iloc[i]], fields) for i in range(test_df.shape[0])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO9CNp44Y92p"
      },
      "source": [
        "OpusDataset_train = data.Dataset(train_example, fields)\r\n",
        "OpusDataset_dev = data.Dataset(test_example, fields)\r\n",
        "OpusDataset_valid = data.Dataset(valid_example, fields)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnzC04ICY9xg",
        "outputId": "7d4b84d8-a10b-4558-f89a-66f6e2c16094"
      },
      "source": [
        "(len(OpusDataset_train), len(OpusDataset_dev),len(OpusDataset_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(576303, 914, 943)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RFANLg0ZvOw"
      },
      "source": [
        "train_data = OpusDataset_train\r\n",
        "test_data = OpusDataset_dev\r\n",
        "valid_data = OpusDataset_valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygsyN63BZoPW"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq = 2)\r\n",
        "TRG.build_vocab(train_data, min_freq = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIIrvrd7ZoMc"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9WNqUJVZ4x2"
      },
      "source": [
        "BATCH_SIZE = 32\r\n",
        "\r\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\r\n",
        "    (train_data, valid_data, test_data), \r\n",
        "    batch_size = BATCH_SIZE,\r\n",
        "    sort_key=lambda x : len(x.English),\r\n",
        "    sort_within_batch=False, \r\n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c73ntRU7mbH4"
      },
      "source": [
        "class Seq2Seq(nn.Module):\r\n",
        "    def __init__(self, encoder, decoder, device):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.encoder = encoder\r\n",
        "        self.decoder = decoder\r\n",
        "        self.device = device\r\n",
        "        \r\n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\r\n",
        "        \r\n",
        "        #src = [src len, batch size]\r\n",
        "        #trg = [trg len, batch size]\r\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\r\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\r\n",
        "        \r\n",
        "        batch_size = src.shape[1]\r\n",
        "        trg_len = trg.shape[0]\r\n",
        "        trg_vocab_size = self.decoder.output_dim\r\n",
        "        \r\n",
        "        #tensor to store decoder outputs\r\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\r\n",
        "        \r\n",
        "        #encoder_outputs is all hidden states of the input sequence, back and forwards\r\n",
        "        #hidden is the final forward and backward hidden states, passed through a linear layer\r\n",
        "        encoder_outputs, hidden = self.encoder(src)\r\n",
        "                \r\n",
        "        #first input to the decoder is the <sos> tokens\r\n",
        "        input = trg[0,:]\r\n",
        "        \r\n",
        "        for t in range(1, trg_len):\r\n",
        "            \r\n",
        "            #insert input token embedding, previous hidden state and all encoder hidden states\r\n",
        "            #receive output tensor (predictions) and new hidden state\r\n",
        "            output, hidden = self.decoder(input, hidden, encoder_outputs)\r\n",
        "            \r\n",
        "            #place predictions in a tensor holding predictions for each token\r\n",
        "            outputs[t] = output\r\n",
        "            \r\n",
        "            #decide if we are going to use teacher forcing or not\r\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\r\n",
        "            \r\n",
        "            #get the highest predicted token from our predictions\r\n",
        "            top1 = output.argmax(1) \r\n",
        "            \r\n",
        "            #if teacher forcing, use actual next token as next input\r\n",
        "            #if not, use predicted token\r\n",
        "            input = trg[t] if teacher_force else top1\r\n",
        "\r\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m8uqfmkZ4vM"
      },
      "source": [
        "class Encoder(nn.Module):\r\n",
        "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\r\n",
        "        \r\n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\r\n",
        "        \r\n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, src):\r\n",
        "        \r\n",
        "        #src = [src len, batch size]\r\n",
        "        \r\n",
        "        embedded = self.dropout(self.embedding(src))\r\n",
        "        \r\n",
        "        #embedded = [src len, batch size, emb dim]\r\n",
        "        \r\n",
        "        outputs, hidden = self.rnn(embedded)\r\n",
        "                \r\n",
        "        #outputs = [src len, batch size, hid dim * num directions]\r\n",
        "        #hidden = [n layers * num directions, batch size, hid dim]\r\n",
        "        \r\n",
        "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\r\n",
        "        #outputs are always from the last layer\r\n",
        "        \r\n",
        "        #hidden [-2, :, : ] is the last of the forwards RNN \r\n",
        "        #hidden [-1, :, : ] is the last of the backwards RNN\r\n",
        "        \r\n",
        "        #initial decoder hidden is final hidden state of the forwards and backwards \r\n",
        "        #  encoder RNNs fed through a linear layer\r\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\r\n",
        "        \r\n",
        "        #outputs = [src len, batch size, enc hid dim * 2]\r\n",
        "        #hidden = [batch size, dec hid dim]\r\n",
        "        \r\n",
        "        return outputs, hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipRDDCKCZ4sX"
      },
      "source": [
        "class Attention(nn.Module):\r\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\r\n",
        "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\r\n",
        "        \r\n",
        "    def forward(self, hidden, encoder_outputs):\r\n",
        "        \r\n",
        "        #hidden = [batch size, dec hid dim]\r\n",
        "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\r\n",
        "        \r\n",
        "        batch_size = encoder_outputs.shape[1]\r\n",
        "        src_len = encoder_outputs.shape[0]\r\n",
        "        \r\n",
        "        #repeat decoder hidden state src_len times\r\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\r\n",
        "        \r\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\r\n",
        "        \r\n",
        "        #hidden = [batch size, src len, dec hid dim]\r\n",
        "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\r\n",
        "        \r\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \r\n",
        "        \r\n",
        "        #energy = [batch size, src len, dec hid dim]\r\n",
        "\r\n",
        "        attention = self.v(energy).squeeze(2)\r\n",
        "        \r\n",
        "        #attention= [batch size, src len]\r\n",
        "        \r\n",
        "        return F.softmax(attention, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuPvb6QUmtDG"
      },
      "source": [
        "class Decoder(nn.Module):\r\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.output_dim = output_dim\r\n",
        "        self.attention = attention\r\n",
        "        \r\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\r\n",
        "        \r\n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\r\n",
        "        \r\n",
        "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, input, hidden, encoder_outputs):\r\n",
        "             \r\n",
        "        #input = [batch size]\r\n",
        "        #hidden = [batch size, dec hid dim]\r\n",
        "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\r\n",
        "        \r\n",
        "        input = input.unsqueeze(0)\r\n",
        "        \r\n",
        "        #input = [1, batch size]\r\n",
        "        \r\n",
        "        embedded = self.dropout(self.embedding(input))\r\n",
        "        \r\n",
        "        #embedded = [1, batch size, emb dim]\r\n",
        "        \r\n",
        "        a = self.attention(hidden, encoder_outputs)\r\n",
        "                \r\n",
        "        #a = [batch size, src len]\r\n",
        "        \r\n",
        "        a = a.unsqueeze(1)\r\n",
        "        \r\n",
        "        #a = [batch size, 1, src len]\r\n",
        "        \r\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\r\n",
        "        \r\n",
        "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\r\n",
        "        \r\n",
        "        weighted = torch.bmm(a, encoder_outputs)\r\n",
        "        \r\n",
        "        #weighted = [batch size, 1, enc hid dim * 2]\r\n",
        "        \r\n",
        "        weighted = weighted.permute(1, 0, 2)\r\n",
        "        \r\n",
        "        #weighted = [1, batch size, enc hid dim * 2]\r\n",
        "        \r\n",
        "        rnn_input = torch.cat((embedded, weighted), dim = 2)\r\n",
        "        \r\n",
        "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\r\n",
        "            \r\n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\r\n",
        "        \r\n",
        "        #output = [seq len, batch size, dec hid dim * n directions]\r\n",
        "        #hidden = [n layers * n directions, batch size, dec hid dim]\r\n",
        "        \r\n",
        "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\r\n",
        "        #output = [1, batch size, dec hid dim]\r\n",
        "        #hidden = [1, batch size, dec hid dim]\r\n",
        "        #this also means that output == hidden\r\n",
        "        assert (output == hidden).all()\r\n",
        "        \r\n",
        "        embedded = embedded.squeeze(0)\r\n",
        "        output = output.squeeze(0)\r\n",
        "        weighted = weighted.squeeze(0)\r\n",
        "        \r\n",
        "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\r\n",
        "        \r\n",
        "        #prediction = [batch size, output dim]\r\n",
        "        \r\n",
        "        return prediction, hidden.squeeze(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFlNcPVwrwoo"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\r\n",
        "OUTPUT_DIM = len(TRG.vocab)\r\n",
        "#ENC_EMB_DIM = 256\r\n",
        "#DEC_EMB_DIM = 256\r\n",
        "ENC_EMB_DIM = 128\r\n",
        "DEC_EMB_DIM = 128\r\n",
        "#ENC_HID_DIM = 512\r\n",
        "#DEC_HID_DIM = 512\r\n",
        "ENC_HID_DIM = 256\r\n",
        "DEC_HID_DIM = 256\r\n",
        "ENC_DROPOUT = 0.5\r\n",
        "DEC_DROPOUT = 0.5\r\n",
        "\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "\r\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\r\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\r\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\r\n",
        "\r\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDli6Hd_rwk-",
        "outputId": "84603558-41ba-41a8-944b-d15371acef68"
      },
      "source": [
        "def init_weights(m):\r\n",
        "    for name, param in m.named_parameters():\r\n",
        "        nn.init.normal_(param.data, mean=0, std=0.01)\r\n",
        "        \r\n",
        "model.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(32384, 128)\n",
              "    (rnn): GRU(128, 256, bidirectional=True)\n",
              "    (fc): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=768, out_features=256, bias=True)\n",
              "      (v): Linear(in_features=256, out_features=1, bias=False)\n",
              "    )\n",
              "    (embedding): Embedding(44916, 128)\n",
              "    (rnn): GRU(640, 256)\n",
              "    (fc_out): Linear(in_features=896, out_features=44916, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvtYFW8krwh4",
        "outputId": "2c1055f7-2e79-4142-9288-5b32e63072c7"
      },
      "source": [
        "def count_parameters(model):\r\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "\r\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 51,795,060 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUZCEPlSrwfA"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yft3_2Xqrwcu"
      },
      "source": [
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeTMkHVlrwZZ"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\r\n",
        "    \r\n",
        "    model.train()\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    \r\n",
        "    for i, batch in enumerate(iterator):\r\n",
        "        \r\n",
        "        src = batch.English\r\n",
        "        trg = batch.Spanish\r\n",
        "        \r\n",
        "        optimizer.zero_grad()\r\n",
        "        \r\n",
        "        output = model(src, trg)\r\n",
        "        \r\n",
        "        #trg = [trg len, batch size]\r\n",
        "        #output = [trg len, batch size, output dim]\r\n",
        "        \r\n",
        "        output_dim = output.shape[-1]\r\n",
        "        \r\n",
        "        output = output[1:].view(-1, output_dim)\r\n",
        "        trg = trg[1:].view(-1)\r\n",
        "        \r\n",
        "        #trg = [(trg len - 1) * batch size]\r\n",
        "        #output = [(trg len - 1) * batch size, output dim]\r\n",
        "        \r\n",
        "        loss = criterion(output, trg)\r\n",
        "        \r\n",
        "        loss.backward()\r\n",
        "        \r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\r\n",
        "        \r\n",
        "        optimizer.step()\r\n",
        "        \r\n",
        "        epoch_loss += loss.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am6bMBE6rwXj"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\r\n",
        "    \r\n",
        "    model.eval()\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "    \r\n",
        "        for i, batch in enumerate(iterator):\r\n",
        "\r\n",
        "            src = batch.English\r\n",
        "            trg = batch.Spanish\r\n",
        "\r\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\r\n",
        "\r\n",
        "            #trg = [trg len, batch size]\r\n",
        "            #output = [trg len, batch size, output dim]\r\n",
        "\r\n",
        "            output_dim = output.shape[-1]\r\n",
        "            \r\n",
        "            output = output[1:].view(-1, output_dim)\r\n",
        "            trg = trg[1:].view(-1)\r\n",
        "\r\n",
        "            #trg = [(trg len - 1) * batch size]\r\n",
        "            #output = [(trg len - 1) * batch size, output dim]\r\n",
        "\r\n",
        "            loss = criterion(output, trg)\r\n",
        "\r\n",
        "            epoch_loss += loss.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63yI5uV4rwWK"
      },
      "source": [
        "def epoch_time(start_time, end_time):\r\n",
        "    elapsed_time = end_time - start_time\r\n",
        "    elapsed_mins = int(elapsed_time / 60)\r\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\r\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMkPRSwvrwRQ",
        "outputId": "5c0a48dc-7acf-4c71-c418-4e2e0cdac561"
      },
      "source": [
        "N_EPOCHS = 10\r\n",
        "CLIP = 1\r\n",
        "\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "for epoch in range(N_EPOCHS):\r\n",
        "    \r\n",
        "    start_time = time.time()\r\n",
        "    \r\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\r\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\r\n",
        "    \r\n",
        "    end_time = time.time()\r\n",
        "    \r\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\r\n",
        "    \r\n",
        "    if valid_loss < best_valid_loss:\r\n",
        "        best_valid_loss = valid_loss\r\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\r\n",
        "    \r\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\r\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\r\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 35m 0s\n",
            "\tTrain Loss: 3.530 | Train PPL:  34.128\n",
            "\t Val. Loss: 3.651 |  Val. PPL:  38.515\n",
            "Epoch: 02 | Time: 35m 8s\n",
            "\tTrain Loss: 2.806 | Train PPL:  16.539\n",
            "\t Val. Loss: 3.584 |  Val. PPL:  36.015\n",
            "Epoch: 03 | Time: 34m 44s\n",
            "\tTrain Loss: 2.621 | Train PPL:  13.754\n",
            "\t Val. Loss: 3.586 |  Val. PPL:  36.105\n",
            "Epoch: 04 | Time: 34m 17s\n",
            "\tTrain Loss: 2.522 | Train PPL:  12.458\n",
            "\t Val. Loss: 3.560 |  Val. PPL:  35.148\n",
            "Epoch: 05 | Time: 34m 16s\n",
            "\tTrain Loss: 2.457 | Train PPL:  11.672\n",
            "\t Val. Loss: 3.631 |  Val. PPL:  37.732\n",
            "Epoch: 06 | Time: 34m 16s\n",
            "\tTrain Loss: 2.407 | Train PPL:  11.103\n",
            "\t Val. Loss: 3.676 |  Val. PPL:  39.491\n",
            "Epoch: 07 | Time: 34m 18s\n",
            "\tTrain Loss: 2.367 | Train PPL:  10.664\n",
            "\t Val. Loss: 3.654 |  Val. PPL:  38.626\n",
            "Epoch: 08 | Time: 34m 16s\n",
            "\tTrain Loss: 2.342 | Train PPL:  10.398\n",
            "\t Val. Loss: 3.612 |  Val. PPL:  37.044\n",
            "Epoch: 09 | Time: 34m 16s\n",
            "\tTrain Loss: 2.318 | Train PPL:  10.155\n",
            "\t Val. Loss: 3.622 |  Val. PPL:  37.397\n",
            "Epoch: 10 | Time: 35m 6s\n",
            "\tTrain Loss: 2.296 | Train PPL:   9.931\n",
            "\t Val. Loss: 3.691 |  Val. PPL:  40.084\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qDLZzDorwOL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2049e2c6-9470-4bbd-e7db-a50a2d076a45"
      },
      "source": [
        "model.load_state_dict(torch.load('tut2-model.pt'))\r\n",
        "\r\n",
        "test_loss = evaluate(model, test_iterator, criterion)\r\n",
        "\r\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 3.639 | Test PPL:  38.070 |\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}