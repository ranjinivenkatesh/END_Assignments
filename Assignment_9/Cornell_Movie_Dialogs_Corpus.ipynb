{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "Copy of Cornell_Movie_Dialogs_Corpus.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranjinivenkatesh/END_Assignments/blob/main/Assignment_9/Cornell_Movie_Dialogs_Corpus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay6Bu88Nkhod",
        "outputId": "95dfed0b-8ee1-4ddc-f671-872d10814243"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Dec 28 18:18:11 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8    10W /  70W |     10MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUnMLdevEzFT"
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "#from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import unicodedata\n",
        "import codecs\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_Ova75wHKWy",
        "outputId": "f218017b-d9e2-40d1-a9fe-88edcfb37ea7"
      },
      "source": [
        "!wget \"http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-28 18:18:11--  http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
            "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.36\n",
            "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.36|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9916637 (9.5M) [application/zip]\n",
            "Saving to: ‘cornell_movie_dialogs_corpus.zip’\n",
            "\n",
            "cornell_movie_dialo 100%[===================>]   9.46M  12.8MB/s    in 0.7s    \n",
            "\n",
            "2020-12-28 18:18:12 (12.8 MB/s) - ‘cornell_movie_dialogs_corpus.zip’ saved [9916637/9916637]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xy_XgNUUHKOg",
        "outputId": "af973525-4680-4910-c5d3-5057d6c8d15e"
      },
      "source": [
        "!unzip 'cornell_movie_dialogs_corpus.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cornell_movie_dialogs_corpus.zip\n",
            "   creating: cornell movie-dialogs corpus/\n",
            "  inflating: cornell movie-dialogs corpus/.DS_Store  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/cornell movie-dialogs corpus/\n",
            "  inflating: __MACOSX/cornell movie-dialogs corpus/._.DS_Store  \n",
            "  inflating: cornell movie-dialogs corpus/chameleons.pdf  \n",
            "  inflating: __MACOSX/cornell movie-dialogs corpus/._chameleons.pdf  \n",
            "  inflating: cornell movie-dialogs corpus/movie_characters_metadata.txt  \n",
            "  inflating: cornell movie-dialogs corpus/movie_conversations.txt  \n",
            "  inflating: cornell movie-dialogs corpus/movie_lines.txt  \n",
            "  inflating: cornell movie-dialogs corpus/movie_titles_metadata.txt  \n",
            "  inflating: cornell movie-dialogs corpus/raw_script_urls.txt  \n",
            "  inflating: cornell movie-dialogs corpus/README.txt  \n",
            "  inflating: __MACOSX/cornell movie-dialogs corpus/._README.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP1ernp1cAGm",
        "outputId": "25e7b12b-f67c-4386-e066-ea0055addb3d"
      },
      "source": [
        "USE_CUDA = torch.cuda.is_available()\r\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\r\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ8j0iPXHRn3"
      },
      "source": [
        "corpus = \"cornell movie-dialogs corpus\"\r\n",
        "\r\n",
        "lines_filepath = os.path.join('cornell movie-dialogs corpus', 'movie_lines.txt')\r\n",
        "conv_filepath = os.path.join('cornell movie-dialogs corpus', 'movie_conversations.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Wpc-somJXdj",
        "outputId": "ce9d569c-73db-4f87-ccab-62cd99c821fe"
      },
      "source": [
        "# Visualize some lines\r\n",
        "def printLines(file, n=10):\r\n",
        "    with open(file, 'rb') as datafile:\r\n",
        "        lines = datafile.readlines()\r\n",
        "    for line in lines[:n]:\r\n",
        "        print(line.strip())\r\n",
        "\r\n",
        "printLines(lines_filepath)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!'\n",
            "b'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!'\n",
            "b'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.'\n",
            "b'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?'\n",
            "b\"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\"\n",
            "b'L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow'\n",
            "b\"L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\"\n",
            "b'L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No'\n",
            "b'L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?'\n",
            "b'L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGn4iPTmJXUC"
      },
      "source": [
        "# Splits each line of the file into a dictionary of fields\r\n",
        "def loadLines(fileName, fields):\r\n",
        "    lines = {}\r\n",
        "    with open(fileName, 'r', encoding='iso-8859-1') as f:\r\n",
        "        for line in f:\r\n",
        "            values = line.split(\" +++$+++ \")\r\n",
        "            # Extract fields\r\n",
        "            lineObj = {}\r\n",
        "            for i, field in enumerate(fields):\r\n",
        "                lineObj[field] = values[i]\r\n",
        "            lines[lineObj['lineID']] = lineObj\r\n",
        "    return lines\r\n",
        "\r\n",
        "\r\n",
        "# Groups fields of lines from `loadLines` into conversations based on *movie_conversations.txt*\r\n",
        "def loadConversations(fileName, lines, fields):\r\n",
        "    conversations = []\r\n",
        "    with open(fileName, 'r', encoding='iso-8859-1') as f:\r\n",
        "        for line in f:\r\n",
        "            values = line.split(\" +++$+++ \")\r\n",
        "            # Extract fields\r\n",
        "            convObj = {}\r\n",
        "            for i, field in enumerate(fields):\r\n",
        "                convObj[field] = values[i]\r\n",
        "            # Convert string to list (convObj[\"utteranceIDs\"] == \"['L598485', 'L598486', ...]\")\r\n",
        "            lineIds = eval(convObj[\"utteranceIDs\"])\r\n",
        "            # Reassemble lines\r\n",
        "            convObj[\"lines\"] = []\r\n",
        "            for lineId in lineIds:\r\n",
        "                convObj[\"lines\"].append(lines[lineId])\r\n",
        "            conversations.append(convObj)\r\n",
        "    return conversations\r\n",
        "\r\n",
        "\r\n",
        "# Extracts pairs of sentences from conversations\r\n",
        "def extractSentencePairs(conversations):\r\n",
        "    qa_pairs = []\r\n",
        "    for conversation in conversations:\r\n",
        "        # Iterate over all the lines of the conversation\r\n",
        "        for i in range(len(conversation[\"lines\"]) - 1):  # We ignore the last line (no answer for it)\r\n",
        "            inputLine = conversation[\"lines\"][i][\"text\"].strip()\r\n",
        "            targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\r\n",
        "            # Filter wrong samples (if one of the lists is empty)\r\n",
        "            if inputLine and targetLine:\r\n",
        "                qa_pairs.append([inputLine, targetLine])\r\n",
        "    return qa_pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV_oLslVJSp8",
        "outputId": "af5a2a97-4314-40ed-c4e7-163c4937e8b1"
      },
      "source": [
        "# Define path to new file\r\n",
        "datafile = os.path.join(corpus, \"formatted_movie_lines.txt\")\r\n",
        "\r\n",
        "delimiter = '@'\r\n",
        "# Unescape the delimiter\r\n",
        "delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\r\n",
        "\r\n",
        "# Initialize lines dict, conversations list, and field ids\r\n",
        "lines = {}\r\n",
        "conversations = []\r\n",
        "MOVIE_LINES_FIELDS = [\"lineID\", \"characterID\", \"movieID\", \"character\", \"text\"]\r\n",
        "MOVIE_CONVERSATIONS_FIELDS = [\"character1ID\", \"character2ID\", \"movieID\", \"utteranceIDs\"]\r\n",
        "\r\n",
        "# Load lines and process conversations\r\n",
        "print(\"\\nProcessing corpus...\")\r\n",
        "lines = loadLines(os.path.join(corpus, \"movie_lines.txt\"), MOVIE_LINES_FIELDS)\r\n",
        "print(\"\\nLoading conversations...\")\r\n",
        "conversations = loadConversations(os.path.join(corpus, \"movie_conversations.txt\"),\r\n",
        "                                  lines, MOVIE_CONVERSATIONS_FIELDS)\r\n",
        "\r\n",
        "# Write new csv file\r\n",
        "print(\"\\nWriting newly formatted file...\")\r\n",
        "with open(datafile, 'w', encoding='utf-8') as outputfile:\r\n",
        "    writer = csv.writer(outputfile, delimiter=delimiter, lineterminator='\\n')\r\n",
        "    for pair in extractSentencePairs(conversations):\r\n",
        "        writer.writerow(pair)\r\n",
        "\r\n",
        "# Print a sample of lines\r\n",
        "print(\"\\nSample lines from file:\")\r\n",
        "printLines(datafile)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Processing corpus...\n",
            "\n",
            "Loading conversations...\n",
            "\n",
            "Writing newly formatted file...\n",
            "\n",
            "Sample lines from file:\n",
            "b\"Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.@Well, I thought we'd start with pronunciation, if that's okay with you.\"\n",
            "b\"Well, I thought we'd start with pronunciation, if that's okay with you.@Not the hacking and gagging and spitting part.  Please.\"\n",
            "b\"Not the hacking and gagging and spitting part.  Please.@Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\"\n",
            "b\"You're asking me out.  That's so cute. What's your name again?@Forget it.\"\n",
            "b\"No, no, it's my fault -- we didn't have a proper introduction ---@Cameron.\"\n",
            "b\"Cameron.@The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\"\n",
            "b\"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.@Seems like she could get a date easy enough...\"\n",
            "b'Why?@Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.'\n",
            "b\"Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.@That's a shame.\"\n",
            "b'Gosh, if only we could find Kat a boyfriend...@Let me see what I can do.'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eov9k8XU8Z2J"
      },
      "source": [
        "# Turn a Unicode string to plain ASCII\r\n",
        "def unicodeToAscii(s):\r\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "unV2BcNd8fXT",
        "outputId": "6132af18-83ed-42a2-eec7-b9d973db19cb"
      },
      "source": [
        "# Test the function\r\n",
        "unicodeToAscii('Montréal')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Montreal'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4smXltQ8Zzk"
      },
      "source": [
        "# String processing\r\n",
        "def normalizeString(s):\r\n",
        "    s = unicodeToAscii(s.lower().strip())\r\n",
        "    # Replace symbols with a white space + symbol\r\n",
        "    s = re.sub(r'([.!?])', r' \\1', s)\r\n",
        "    # Remove non-sequence characters\r\n",
        "    s = re.sub(r'[^a-zA-Z.!?\\']+', r' ', s)\r\n",
        "    # remove whitespaces\r\n",
        "    s = re.sub(r'\\s+', r' ', s).strip()\r\n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "f8C1UVo28Zv7",
        "outputId": "de837326-b0da-4be5-969c-05c29ecdef1d"
      },
      "source": [
        "# Test\r\n",
        "normalizeString('aaa243998!s\"s s\\'s df?? ? 1a')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"aaa !s s s's df ? ? ? a\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BReQ03k48ZsV",
        "outputId": "dd151075-372d-41ae-aa9d-e0e88323d57a"
      },
      "source": [
        "datafile = os.path.join('cornell movie-dialogs corpus', 'formatted_movie_lines.txt')\r\n",
        "# Read the file and split into lines\r\n",
        "print('Reading and processing file.....please wait')\r\n",
        "lines = open(datafile, encoding='utf-8').read().strip().split('\\n')\r\n",
        "#split every line into pairs and normalize\r\n",
        "pairs = [[normalizeString(s) for s in pair.split('@')] for pair in lines]\r\n",
        "print('Done Reading!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading and processing file.....please wait\n",
            "Done Reading!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHPpJpRk8-ra",
        "outputId": "9a42fd9c-deae-4560-fd24-49850d7aae94"
      },
      "source": [
        "pairs[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['can we make this quick ? roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad . again .',\n",
              "  \"well i thought we'd start with pronunciation if that's okay with you .\"],\n",
              " [\"well i thought we'd start with pronunciation if that's okay with you .\",\n",
              "  'not the hacking and gagging and spitting part . please .'],\n",
              " ['not the hacking and gagging and spitting part . please .',\n",
              "  \"okay . . . then how 'bout we try out some french cuisine . saturday ? night ?\"],\n",
              " [\"you're asking me out . that's so cute . what's your name again ?\",\n",
              "  'forget it .'],\n",
              " [\"no no it's my fault we didn't have a proper introduction\", 'cameron .']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_i0nryS8-nc"
      },
      "source": [
        "MAX_LENGTH = 10\r\n",
        "def filterPair(p):\r\n",
        "    return len(p[0].split()) < MAX_LENGTH and len(p[1].split()) < MAX_LENGTH\r\n",
        "\r\n",
        "# filter pairs using filter pair condition\r\n",
        "def filterPairs(pairs):\r\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeLm9bfT9Ein",
        "outputId": "098b072c-d3a0-4c04-b2bd-d4472b944e00"
      },
      "source": [
        "pairs = [pair for pair in pairs if len(pair)>1]\r\n",
        "print(f'There are {len(pairs)} pairs/conversations in the dataset.')\r\n",
        "pairs = filterPairs(pairs)\r\n",
        "print(f'After filtering, there are {len(pairs)} pairs/conversations in the dataset')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 221282 pairs/conversations in the dataset.\n",
            "After filtering, there are 70009 pairs/conversations in the dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5SPT5qB9EfL",
        "outputId": "9af7dd06-ed36-4597-e7d1-2ef9d0526dfd"
      },
      "source": [
        "datafile = os.path.join('cornell movie-dialogs corpus', 'formatted_truncated_movie_lines.csv')\r\n",
        "\r\n",
        "#write new csv file\r\n",
        "#corrupt_list = [6823, 6824, 6825, 6826]\r\n",
        "print('\\nWriting newly formatted file')\r\n",
        "with open(datafile, 'w') as f:\r\n",
        "    #writer = csv.writer(f, delimiter='@')\r\n",
        "    writer = csv.writer(f)\r\n",
        "    writer.writerow([\"Dialogue_A\", \"Dialogue_B\"])\r\n",
        "    for count, pair in enumerate(pairs):\r\n",
        "        #if count not in corrupt_list:\r\n",
        "          writer.writerow(pair)\r\n",
        "        #else:\r\n",
        "         # print(\"not writing\")\r\n",
        "print('Done writing to a file')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Writing newly formatted file\n",
            "Done writing to a file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfbGfra38-ir",
        "outputId": "4832758d-f5a5-472a-ce55-7bc3a347a8e6"
      },
      "source": [
        "# Print a sample of lines\r\n",
        "#datafile = os.path.join('cornell movie-dialogs corpus', 'formatted_truncated_movie_lines.csv')\r\n",
        "print(\"\\nSample lines from file:\")\r\n",
        "#printLines(datafile)\r\n",
        "\r\n",
        "with open(datafile, 'rb') as f:\r\n",
        "    lines = f.readlines()\r\n",
        "    #print(lines[392:394])\r\n",
        "    for line in range(392,396):\r\n",
        "      print(lines[line])\r\n",
        "        #print(line.strip())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Sample lines from file:\n",
            "b\"mouth's clean too .,clean ?\\r\\n\"\n",
            "b\"clean ?,don't blow your nose !\\r\\n\"\n",
            "b'he knew all along .,what ? ?\\r\\n'\n",
            "b'yeah ?,maybe you can be his stand in .\\r\\n'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btsrswOo8-dN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "5PdzcEesbtVt",
        "outputId": "17be545f-7403-40d4-86aa-42ee05f92ae7"
      },
      "source": [
        "#df = pd.read_csv(datafile, delimiter='@', sep='@', engine='python')\r\n",
        "#df = pd.read_csv(datafile, sep='@')\r\n",
        "df = pd.read_csv(datafile)\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dialogue_A</th>\n",
              "      <th>Dialogue_B</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>that's because it's such a nice one .</td>\n",
              "      <td>forget french .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>there .</td>\n",
              "      <td>where ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>you have my word . as a gentleman</td>\n",
              "      <td>you're sweet .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hi .</td>\n",
              "      <td>looks like things worked out tonight huh ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>you know chastity ?</td>\n",
              "      <td>i believe we share an art instructor</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              Dialogue_A                                  Dialogue_B\n",
              "0  that's because it's such a nice one .                             forget french .\n",
              "1                                there .                                     where ?\n",
              "2      you have my word . as a gentleman                              you're sweet .\n",
              "3                                   hi .  looks like things worked out tonight huh ?\n",
              "4                    you know chastity ?        i believe we share an art instructor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEXaTOdCbtK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49872972-c5c8-46e9-906d-b26f65bb0c6a"
      },
      "source": [
        "print(df.shape)\r\n",
        "df.iloc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(70009, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dialogue_A    that's because it's such a nice one .\n",
              "Dialogue_B                          forget french .\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teAtxiOagQ5Z"
      },
      "source": [
        "# Use same field for both columns since they have a shared vocabulary\r\n",
        "TEXT = torchtext.data.Field(\r\n",
        "    tokenize='spacy',\r\n",
        "    lower=True,\r\n",
        "    init_token='<sos>', \r\n",
        "    eos_token='<eos>'\r\n",
        ")\r\n",
        "\r\n",
        "fields = [('Dialogue_A', TEXT), ('Dialogue_B', TEXT)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6zrTjFmgQ2m",
        "outputId": "84513009-afae-4237-9e11-d3b1e386e930"
      },
      "source": [
        "start = time.time()\r\n",
        "dataset = torchtext.data.TabularDataset(\r\n",
        "    path=datafile,\r\n",
        "    format='CSV',\r\n",
        "    fields=fields,\r\n",
        "    skip_header=True\r\n",
        ")\r\n",
        "end = time.time()\r\n",
        "print(f'Duration: {end - start}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Duration: 4.407198190689087\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOhZoHmDgQy5",
        "outputId": "39155dfa-cfa9-48d0-ab4e-d7674285cb12"
      },
      "source": [
        "(train, valid) = dataset.split(split_ratio=[0.85, 0.15])\r\n",
        "print(len(train), len(valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59508 10501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjTcwd-UgQwZ",
        "outputId": "66835acd-91b9-483b-9b9a-5d9fd9faed1c"
      },
      "source": [
        "vars(train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Dialogue_A': ['george', 'you', 'look', 'terrible', '.'],\n",
              " 'Dialogue_B': ['yeah', 'well', '.', '.', '.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNqRaO2ZgQrQ",
        "outputId": "ffa2363b-f71f-4bd1-b523-8c8e82468b2c"
      },
      "source": [
        "#MAX_VOCAB_SIZE = 10_000\r\n",
        "#TEXT.build_vocab(train, max_size=MAX_VOCAB_SIZE)\r\n",
        "TEXT.build_vocab(train)\r\n",
        "print(f'Size of vocab: {len(TEXT.vocab)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of vocab: 17900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI73E9UTgQn0"
      },
      "source": [
        "BATCH_SIZE = 128\r\n",
        "\r\n",
        "train_iterator, valid_iterator = torchtext.data.BucketIterator.splits(\r\n",
        "    (train, valid),\r\n",
        "    batch_size = BATCH_SIZE,\r\n",
        "    sort_key=lambda x: len(x.Dialogue_A),\r\n",
        "    device = device\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTRmmOsnhyzf"
      },
      "source": [
        "class Encoder(nn.Module):\r\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, dropout):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.hid_dim = hid_dim\r\n",
        "        \r\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim) #no dropout as only one layer!\r\n",
        "        \r\n",
        "        self.rnn = nn.GRU(emb_dim, hid_dim)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, src):\r\n",
        "        \r\n",
        "        #src = [src len, batch size]\r\n",
        "        \r\n",
        "        embedded = self.dropout(self.embedding(src))\r\n",
        "        \r\n",
        "        #embedded = [src len, batch size, emb dim]\r\n",
        "        \r\n",
        "        outputs, hidden = self.rnn(embedded) #no cell state!\r\n",
        "        \r\n",
        "        #outputs = [src len, batch size, hid dim * n directions]\r\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\r\n",
        "        \r\n",
        "        #outputs are always from the top hidden layer\r\n",
        "        \r\n",
        "        return hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOgBET9mhyvL"
      },
      "source": [
        "class Decoder(nn.Module):\r\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, dropout):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.hid_dim = hid_dim\r\n",
        "        self.output_dim = output_dim\r\n",
        "        \r\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\r\n",
        "        \r\n",
        "        self.rnn = nn.GRU(emb_dim + hid_dim, hid_dim)\r\n",
        "        \r\n",
        "        self.fc_out = nn.Linear(emb_dim + hid_dim * 2, output_dim)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, input, hidden, context):\r\n",
        "        \r\n",
        "        #input = [batch size]\r\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\r\n",
        "        #context = [n layers * n directions, batch size, hid dim]\r\n",
        "        \r\n",
        "        #n layers and n directions in the decoder will both always be 1, therefore:\r\n",
        "        #hidden = [1, batch size, hid dim]\r\n",
        "        #context = [1, batch size, hid dim]\r\n",
        "        \r\n",
        "        input = input.unsqueeze(0)\r\n",
        "        \r\n",
        "        #input = [1, batch size]\r\n",
        "        \r\n",
        "        embedded = self.dropout(self.embedding(input))\r\n",
        "        \r\n",
        "        #embedded = [1, batch size, emb dim]\r\n",
        "                \r\n",
        "        emb_con = torch.cat((embedded, context), dim = 2)\r\n",
        "            \r\n",
        "        #emb_con = [1, batch size, emb dim + hid dim]\r\n",
        "            \r\n",
        "        output, hidden = self.rnn(emb_con, hidden)\r\n",
        "        \r\n",
        "        #output = [seq len, batch size, hid dim * n directions]\r\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\r\n",
        "        \r\n",
        "        #seq len, n layers and n directions will always be 1 in the decoder, therefore:\r\n",
        "        #output = [1, batch size, hid dim]\r\n",
        "        #hidden = [1, batch size, hid dim]\r\n",
        "        \r\n",
        "        output = torch.cat((embedded.squeeze(0), hidden.squeeze(0), context.squeeze(0)), \r\n",
        "                           dim = 1)\r\n",
        "        \r\n",
        "        #output = [batch size, emb dim + hid dim * 2]\r\n",
        "        \r\n",
        "        prediction = self.fc_out(output)\r\n",
        "        \r\n",
        "        #prediction = [batch size, output dim]\r\n",
        "        \r\n",
        "        return prediction, hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z68WvBCfhyr4"
      },
      "source": [
        "class Seq2Seq(nn.Module):\r\n",
        "    def __init__(self, encoder, decoder, device):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.encoder = encoder\r\n",
        "        self.decoder = decoder\r\n",
        "        self.device = device\r\n",
        "        \r\n",
        "        assert encoder.hid_dim == decoder.hid_dim, \\\r\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\r\n",
        "        \r\n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\r\n",
        "        \r\n",
        "        #src = [src len, batch size]\r\n",
        "        #trg = [trg len, batch size]\r\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\r\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\r\n",
        "        \r\n",
        "        batch_size = trg.shape[1]\r\n",
        "        trg_len = trg.shape[0]\r\n",
        "        trg_vocab_size = self.decoder.output_dim\r\n",
        "        \r\n",
        "        #tensor to store decoder outputs\r\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\r\n",
        "        \r\n",
        "        #last hidden state of the encoder is the context\r\n",
        "        context = self.encoder(src)\r\n",
        "        \r\n",
        "        #context also used as the initial hidden state of the decoder\r\n",
        "        hidden = context\r\n",
        "        \r\n",
        "        #first input to the decoder is the <sos> tokens\r\n",
        "        input = trg[0,:]\r\n",
        "        \r\n",
        "        for t in range(1, trg_len):\r\n",
        "            \r\n",
        "            #insert input token embedding, previous hidden state and the context state\r\n",
        "            #receive output tensor (predictions) and new hidden state\r\n",
        "            output, hidden = self.decoder(input, hidden, context)\r\n",
        "            \r\n",
        "            #place predictions in a tensor holding predictions for each token\r\n",
        "            outputs[t] = output\r\n",
        "            \r\n",
        "            #decide if we are going to use teacher forcing or not\r\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\r\n",
        "            \r\n",
        "            #get the highest predicted token from our predictions\r\n",
        "            top1 = output.argmax(1) \r\n",
        "            \r\n",
        "            #if teacher forcing, use actual next token as next input\r\n",
        "            #if not, use predicted token\r\n",
        "            input = trg[t] if teacher_force else top1\r\n",
        "\r\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEegRGLfhyoe"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\r\n",
        "OUTPUT_DIM = len(TEXT.vocab)\r\n",
        "ENC_EMB_DIM = 128\r\n",
        "DEC_EMB_DIM = 128\r\n",
        "HID_DIM = 256\r\n",
        "ENC_DROPOUT = 0.5\r\n",
        "DEC_DROPOUT = 0.5\r\n",
        "\r\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, ENC_DROPOUT)\r\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, DEC_DROPOUT)\r\n",
        "\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "\r\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aINUXz3h-Xe",
        "outputId": "7567ce2f-2a77-41a8-f8ae-7a93278e0f6a"
      },
      "source": [
        "def init_weights(m):\r\n",
        "    for name, param in m.named_parameters():\r\n",
        "        nn.init.normal_(param.data, mean=0, std=0.01)\r\n",
        "        \r\n",
        "model.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(17900, 128)\n",
              "    (rnn): GRU(128, 256)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(17900, 128)\n",
              "    (rnn): GRU(384, 256)\n",
              "    (fc_out): Linear(in_features=640, out_features=17900, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0kTrW-8h-OU",
        "outputId": "c0518af9-72f4-4a82-ec44-6cd3620421f7"
      },
      "source": [
        "def count_parameters(model):\r\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "\r\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 16,845,804 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDba7gw4h-Kg"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7nrOiAoh-HE"
      },
      "source": [
        "TRG_PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALOT-Ndnh-EF"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\r\n",
        "    \r\n",
        "    model.train()\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    \r\n",
        "    for i, batch in enumerate(iterator):\r\n",
        "        \r\n",
        "        src = batch.Dialogue_A\r\n",
        "        trg = batch.Dialogue_B\r\n",
        "        \r\n",
        "        optimizer.zero_grad()\r\n",
        "        \r\n",
        "        output = model(src, trg)\r\n",
        "        \r\n",
        "        #trg = [trg len, batch size]\r\n",
        "        #output = [trg len, batch size, output dim]\r\n",
        "        \r\n",
        "        output_dim = output.shape[-1]\r\n",
        "        \r\n",
        "        output = output[1:].view(-1, output_dim)\r\n",
        "        trg = trg[1:].view(-1)\r\n",
        "        \r\n",
        "        #trg = [(trg len - 1) * batch size]\r\n",
        "        #output = [(trg len - 1) * batch size, output dim]\r\n",
        "        \r\n",
        "        loss = criterion(output, trg)\r\n",
        "        \r\n",
        "        loss.backward()\r\n",
        "        \r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\r\n",
        "        \r\n",
        "        optimizer.step()\r\n",
        "        \r\n",
        "        epoch_loss += loss.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKs2j6K7iccZ"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\r\n",
        "    \r\n",
        "    model.eval()\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "    \r\n",
        "        for i, batch in enumerate(iterator):\r\n",
        "\r\n",
        "            src = batch.Dialogue_A\r\n",
        "            trg = batch.Dialogue_B\r\n",
        "\r\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\r\n",
        "\r\n",
        "            #trg = [trg len, batch size]\r\n",
        "            #output = [trg len, batch size, output dim]\r\n",
        "\r\n",
        "            output_dim = output.shape[-1]\r\n",
        "            \r\n",
        "            output = output[1:].view(-1, output_dim)\r\n",
        "            trg = trg[1:].view(-1)\r\n",
        "\r\n",
        "            #trg = [(trg len - 1) * batch size]\r\n",
        "            #output = [(trg len - 1) * batch size, output dim]\r\n",
        "\r\n",
        "            loss = criterion(output, trg)\r\n",
        "\r\n",
        "            epoch_loss += loss.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeGvJcpKicZe"
      },
      "source": [
        "def epoch_time(start_time, end_time):\r\n",
        "    elapsed_time = end_time - start_time\r\n",
        "    elapsed_mins = int(elapsed_time / 60)\r\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\r\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yupPBAqTikyf",
        "outputId": "838a703f-a24d-4829-94da-b768a8204be1"
      },
      "source": [
        "N_EPOCHS = 10\r\n",
        "CLIP = 1\r\n",
        "\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "for epoch in range(N_EPOCHS):\r\n",
        "    \r\n",
        "    start_time = time.time()\r\n",
        "    \r\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\r\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\r\n",
        "    \r\n",
        "    end_time = time.time()\r\n",
        "    \r\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\r\n",
        "    \r\n",
        "    if valid_loss < best_valid_loss:\r\n",
        "        best_valid_loss = valid_loss\r\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\r\n",
        "    \r\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\r\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\r\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 57s\n",
            "\tTrain Loss: 4.946 | Train PPL: 140.585\n",
            "\t Val. Loss: 4.936 |  Val. PPL: 139.214\n",
            "Epoch: 02 | Time: 0m 57s\n",
            "\tTrain Loss: 4.504 | Train PPL:  90.405\n",
            "\t Val. Loss: 4.949 |  Val. PPL: 140.994\n",
            "Epoch: 03 | Time: 0m 57s\n",
            "\tTrain Loss: 4.404 | Train PPL:  81.779\n",
            "\t Val. Loss: 4.941 |  Val. PPL: 139.844\n",
            "Epoch: 04 | Time: 0m 57s\n",
            "\tTrain Loss: 4.335 | Train PPL:  76.329\n",
            "\t Val. Loss: 4.973 |  Val. PPL: 144.460\n",
            "Epoch: 05 | Time: 0m 57s\n",
            "\tTrain Loss: 4.247 | Train PPL:  69.893\n",
            "\t Val. Loss: 5.039 |  Val. PPL: 154.242\n",
            "Epoch: 06 | Time: 0m 57s\n",
            "\tTrain Loss: 4.176 | Train PPL:  65.106\n",
            "\t Val. Loss: 5.068 |  Val. PPL: 158.812\n",
            "Epoch: 07 | Time: 0m 57s\n",
            "\tTrain Loss: 4.103 | Train PPL:  60.547\n",
            "\t Val. Loss: 5.056 |  Val. PPL: 157.000\n",
            "Epoch: 08 | Time: 0m 57s\n",
            "\tTrain Loss: 4.038 | Train PPL:  56.712\n",
            "\t Val. Loss: 5.157 |  Val. PPL: 173.651\n",
            "Epoch: 09 | Time: 0m 57s\n",
            "\tTrain Loss: 3.924 | Train PPL:  50.609\n",
            "\t Val. Loss: 5.263 |  Val. PPL: 193.062\n",
            "Epoch: 10 | Time: 0m 57s\n",
            "\tTrain Loss: 3.823 | Train PPL:  45.763\n",
            "\t Val. Loss: 5.321 |  Val. PPL: 204.530\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}