{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Opus100_Corpus.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranjinivenkatesh/END_Assignments/blob/main/Assignment_9/Opus100_Corpus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBwNvWpYAqN-",
        "outputId": "80be8c46-f101-42bc-bb1b-eaccfd90ee44"
      },
      "source": [
        "!wget http://data.statmt.org/opus-100-corpus/v1.0/supervised/en-es/opus.en-es-dev.en\r\n",
        "!wget http://data.statmt.org/opus-100-corpus/v1.0/supervised/en-es/opus.en-es-dev.es\r\n",
        "!wget http://data.statmt.org/opus-100-corpus/v1.0/supervised/en-es/opus.en-es-test.en\r\n",
        "!wget http://data.statmt.org/opus-100-corpus/v1.0/supervised/en-es/opus.en-es-test.es\r\n",
        "!wget http://data.statmt.org/opus-100-corpus/v1.0/supervised/en-es/opus.en-es-train.en\r\n",
        "!wget http://data.statmt.org/opus-100-corpus/v1.0/supervised/en-es/opus.en-es-train.es"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-30 13:50:01--  http://data.statmt.org/opus-100-corpus/v1.0/supervised/en-es/opus.en-es-dev.en\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149835 (146K)\n",
            "Saving to: ‘opus.en-es-dev.en’\n",
            "\n",
            "opus.en-es-dev.en   100%[===================>] 146.32K   353KB/s    in 0.4s    \n",
            "\n",
            "2020-12-30 13:50:02 (353 KB/s) - ‘opus.en-es-dev.en’ saved [149835/149835]\n",
            "\n",
            "--2020-12-30 13:50:02--  http://data.statmt.org/opus-100-corpus/v1.0/supervised/en-es/opus.en-es-dev.es\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 164892 (161K)\n",
            "Saving to: ‘opus.en-es-dev.es’\n",
            "\n",
            "opus.en-es-dev.es   100%[===================>] 161.03K   389KB/s    in 0.4s    \n",
            "\n",
            "2020-12-30 13:50:03 (389 KB/s) - ‘opus.en-es-dev.es’ saved [164892/164892]\n",
            "\n",
            "--2020-12-30 13:50:03--  http://data.statmt.org/opus-100-corpus/v1.0/supervised/en-es/opus.en-es-test.en\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 150105 (147K)\n",
            "Saving to: ‘opus.en-es-test.en’\n",
            "\n",
            "opus.en-es-test.en  100%[===================>] 146.59K   347KB/s    in 0.4s    \n",
            "\n",
            "2020-12-30 13:50:03 (347 KB/s) - ‘opus.en-es-test.en’ saved [150105/150105]\n",
            "\n",
            "--2020-12-30 13:50:04--  http://data.statmt.org/opus-100-corpus/v1.0/supervised/en-es/opus.en-es-test.es\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 164157 (160K)\n",
            "Saving to: ‘opus.en-es-test.es’\n",
            "\n",
            "opus.en-es-test.es  100%[===================>] 160.31K   388KB/s    in 0.4s    \n",
            "\n",
            "2020-12-30 13:50:04 (388 KB/s) - ‘opus.en-es-test.es’ saved [164157/164157]\n",
            "\n",
            "--2020-12-30 13:50:04--  http://data.statmt.org/opus-100-corpus/v1.0/supervised/en-es/opus.en-es-train.en\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 62730250 (60M)\n",
            "Saving to: ‘opus.en-es-train.en’\n",
            "\n",
            "opus.en-es-train.en 100%[===================>]  59.82M  15.5MB/s    in 3.9s    \n",
            "\n",
            "2020-12-30 13:50:08 (15.5 MB/s) - ‘opus.en-es-train.en’ saved [62730250/62730250]\n",
            "\n",
            "--2020-12-30 13:50:08--  http://data.statmt.org/opus-100-corpus/v1.0/supervised/en-es/opus.en-es-train.es\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 67912854 (65M)\n",
            "Saving to: ‘opus.en-es-train.es’\n",
            "\n",
            "opus.en-es-train.es 100%[===================>]  64.77M  16.9MB/s    in 4.1s    \n",
            "\n",
            "2020-12-30 13:50:13 (15.7 MB/s) - ‘opus.en-es-train.es’ saved [67912854/67912854]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYvILlbpBOj7",
        "outputId": "4f4ebda0-c394-46fb-8cbb-b69e7954ee7c"
      },
      "source": [
        "import pandas as pd\r\n",
        "train_en_df = pd.read_csv(\"opus.en-es-train.en\", header = None, sep=\"\\r\\n\", engine=\"python\")\r\n",
        "test_en_df = pd.read_csv(\"opus.en-es-test.en\", header = None, sep=\"\\r\\n\", engine=\"python\")\r\n",
        "valid_en_df = pd.read_csv(\"opus.en-es-dev.en\", header = None, sep=\"\\r\\n\", engine=\"python\")\r\n",
        "#a_dataframe = pd.read_csv(\"opus.en-es-train.en\", header = None, sep='\\r')\r\n",
        "train_en_df, test_en_df, valid_en_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                                        0\n",
              " 0        It was the asbestos in here, that's what did it!\n",
              " 1                                        I'm out of here.\n",
              " 2        One time, I swear I pooped out a stick of chalk.\n",
              " 3                  And I will move, do you understand me?\n",
              " 4                                   - Thank you, my lord.\n",
              " ...                                                   ...\n",
              " 999995  He's not supposed to be here, so... there must...\n",
              " 999996                                     But Loreen is.\n",
              " 999997                                   Charles O'Brien?\n",
              " 999998                                It's... it's great.\n",
              " 999999  In contact with Priscilla Midori and Victor Ma...\n",
              " \n",
              " [1000000 rows x 1 columns],\n",
              "                                                       0\n",
              " 0     If your country produced ODS for this purpose,...\n",
              " 1     ♪ juvie the great man, who else could it be bu...\n",
              " 2                       The home planet is running out.\n",
              " 3                  Oon't girls ever kill their mothers?\n",
              " 4     Humanitarian, recovery and development activities\n",
              " ...                                                 ...\n",
              " 1995                      Megan! I need to talk to you.\n",
              " 1996  - Now that I have your attention, imagine we a...\n",
              " 1997  Do not be concerned, these tips may help you p...\n",
              " 1998                    She started slipping last year.\n",
              " 1999  For if many died through one man's falling awa...\n",
              " \n",
              " [2000 rows x 1 columns],\n",
              "                                                       0\n",
              " 0       I don't even remember what the fight was about.\n",
              " 1     Here are the sites of each of those that have ...\n",
              " 2                    I'm the man who killed Blackbeard.\n",
              " 3                                      Don't get smart.\n",
              " 4     Is there an exact moment in the life of a sold...\n",
              " ...                                                 ...\n",
              " 1995                [Scoffs] I believe the script says,\n",
              " 1996           You didn't even have a case against him.\n",
              " 1997                                    Ok. She's dead.\n",
              " 1998  Opinion of Advocate General Léger delivered on...\n",
              " 1999                               Prepare, yourselves.\n",
              " \n",
              " [2000 rows x 1 columns])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHgbVbl8BOhX",
        "outputId": "1be8b734-50b2-4b26-b20c-1bf9bd3b76f2"
      },
      "source": [
        "train_es_df = pd.read_csv(\"opus.en-es-train.es\", header = None, sep=\"\\r\\n\", engine=\"python\")\r\n",
        "test_es_df = pd.read_csv(\"opus.en-es-test.es\", header = None, sep=\"\\r\\n\", engine=\"python\")\r\n",
        "valid_es_df = pd.read_csv(\"opus.en-es-dev.es\", header = None, sep=\"\\r\\n\", engine=\"python\")\r\n",
        "train_es_df, test_es_df, valid_es_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                                        0\n",
              " 0       Fueron los asbestos aquí. ¡Eso es lo que ocurrió!\n",
              " 1                                         Me voy de aquí.\n",
              " 2              Una vez, juro que cagué una barra de tiza.\n",
              " 3                         Y prefiero mudarme, ¿Entiendes?\n",
              " 4                                              - Gracias.\n",
              " ...                                                   ...\n",
              " 999995  El no debería estar aquí, así que... Debe habe...\n",
              " 999996                                       Pero Loreen.\n",
              " 999997                                - ¿Charles O'Brien?\n",
              " 999998                                         Es genial.\n",
              " 999999  Priscilla Midori y Marcello Victor, los cerebr...\n",
              " \n",
              " [1000000 rows x 1 columns],\n",
              "                                                       0\n",
              " 0     Si su país produjo SAO para estos usos, sírvas...\n",
              " 1     # Juvie el gran hombre, ¿quién podría ser sino...\n",
              " 2                    El planeta madre se está agotando.\n",
              " 3                   Las chicas no matan a sus madres? .\n",
              " 4     Actividades humanitarias, de recuperación y de...\n",
              " ...                                                 ...\n",
              " 1995                    Megan, necesito hablar contigo.\n",
              " 1996  - Le veo interesado, añádale otro cero al precio.\n",
              " 1997  No se preocupe, estos consejos pueden ayudarle...\n",
              " 1998                       Empezó a irse el año pasado.\n",
              " 1999  15Mas no como el delito, tal fué el don: porqu...\n",
              " \n",
              " [2000 rows x 1 columns],\n",
              "                                                       0\n",
              " 0                     No recuerdo por qué fue la pelea.\n",
              " 1     Estos son los sitios en que cada Congreso ha t...\n",
              " 2              Sí. Soy el hombre que mató a Barbanegra.\n",
              " 3                           No te hagas el inteligente.\n",
              " 4     ¿Existe un límite de cuándo se padece y cuándo...\n",
              " ...                                                 ...\n",
              " 1995                       Me parece que el guión dice:\n",
              " 1996           Ni siquiera tenían un caso en su contra.\n",
              " 1997                            Como lo desees, cariño.\n",
              " 1998  Conclusiones del Abogado General Sr. P. Léger,...\n",
              " 1999                                        Preparense.\n",
              " \n",
              " [2000 rows x 1 columns])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tRVfL2hBOfG"
      },
      "source": [
        "train_df = pd.concat([train_en_df, train_es_df], axis=1)\r\n",
        "test_df = pd.concat([test_en_df, test_es_df], axis=1)\r\n",
        "valid_df = pd.concat([valid_en_df, valid_es_df], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3fAk-X3BOcS",
        "outputId": "d31bf6d0-291a-4be3-9ddb-d529a9561261"
      },
      "source": [
        "train_df.columns=[\"English\", \"Spanish\"]\r\n",
        "test_df.columns=[\"English\", \"Spanish\"]\r\n",
        "valid_df.columns=[\"English\", \"Spanish\"]\r\n",
        "train_df, test_df, valid_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                                  English                                            Spanish\n",
              " 0        It was the asbestos in here, that's what did it!  Fueron los asbestos aquí. ¡Eso es lo que ocurrió!\n",
              " 1                                        I'm out of here.                                    Me voy de aquí.\n",
              " 2        One time, I swear I pooped out a stick of chalk.         Una vez, juro que cagué una barra de tiza.\n",
              " 3                  And I will move, do you understand me?                    Y prefiero mudarme, ¿Entiendes?\n",
              " 4                                   - Thank you, my lord.                                         - Gracias.\n",
              " ...                                                   ...                                                ...\n",
              " 999995  He's not supposed to be here, so... there must...  El no debería estar aquí, así que... Debe habe...\n",
              " 999996                                     But Loreen is.                                       Pero Loreen.\n",
              " 999997                                   Charles O'Brien?                                - ¿Charles O'Brien?\n",
              " 999998                                It's... it's great.                                         Es genial.\n",
              " 999999  In contact with Priscilla Midori and Victor Ma...  Priscilla Midori y Marcello Victor, los cerebr...\n",
              " \n",
              " [1000000 rows x 2 columns],\n",
              "                                                 English                                            Spanish\n",
              " 0     If your country produced ODS for this purpose,...  Si su país produjo SAO para estos usos, sírvas...\n",
              " 1     ♪ juvie the great man, who else could it be bu...  # Juvie el gran hombre, ¿quién podría ser sino...\n",
              " 2                       The home planet is running out.                 El planeta madre se está agotando.\n",
              " 3                  Oon't girls ever kill their mothers?                Las chicas no matan a sus madres? .\n",
              " 4     Humanitarian, recovery and development activities  Actividades humanitarias, de recuperación y de...\n",
              " ...                                                 ...                                                ...\n",
              " 1995                      Megan! I need to talk to you.                    Megan, necesito hablar contigo.\n",
              " 1996  - Now that I have your attention, imagine we a...  - Le veo interesado, añádale otro cero al precio.\n",
              " 1997  Do not be concerned, these tips may help you p...  No se preocupe, estos consejos pueden ayudarle...\n",
              " 1998                    She started slipping last year.                       Empezó a irse el año pasado.\n",
              " 1999  For if many died through one man's falling awa...  15Mas no como el delito, tal fué el don: porqu...\n",
              " \n",
              " [2000 rows x 2 columns],\n",
              "                                                 English                                            Spanish\n",
              " 0       I don't even remember what the fight was about.                  No recuerdo por qué fue la pelea.\n",
              " 1     Here are the sites of each of those that have ...  Estos son los sitios en que cada Congreso ha t...\n",
              " 2                    I'm the man who killed Blackbeard.           Sí. Soy el hombre que mató a Barbanegra.\n",
              " 3                                      Don't get smart.                        No te hagas el inteligente.\n",
              " 4     Is there an exact moment in the life of a sold...  ¿Existe un límite de cuándo se padece y cuándo...\n",
              " ...                                                 ...                                                ...\n",
              " 1995                [Scoffs] I believe the script says,                       Me parece que el guión dice:\n",
              " 1996           You didn't even have a case against him.           Ni siquiera tenían un caso en su contra.\n",
              " 1997                                    Ok. She's dead.                            Como lo desees, cariño.\n",
              " 1998  Opinion of Advocate General Léger delivered on...  Conclusiones del Abogado General Sr. P. Léger,...\n",
              " 1999                               Prepare, yourselves.                                        Preparense.\n",
              " \n",
              " [2000 rows x 2 columns])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gOsuv01AwBZ",
        "outputId": "51dcb289-9d2b-4bc2-ee6d-f3e4457371a8"
      },
      "source": [
        "df = train_df\r\n",
        "print(\"train before: \", len(df))\r\n",
        "df['English'] = df['English'].astype('str')\r\n",
        "mask = (df['English'].str.len() <= 40)\r\n",
        "df = df.loc[mask]\r\n",
        "print(\"train after: \", len(df))\r\n",
        "train_df = df\r\n",
        "\r\n",
        "df = test_df\r\n",
        "print(\"test before: \", len(df))\r\n",
        "df['English'] = df['English'].astype('str')\r\n",
        "mask = (df['English'].str.len() <= 40)\r\n",
        "df = df.loc[mask]\r\n",
        "print(\"test after: \", len(df))\r\n",
        "test_df = df\r\n",
        "\r\n",
        "df = valid_df\r\n",
        "print(\"valid before: \", len(df))\r\n",
        "df['English'] = df['English'].astype('str')\r\n",
        "mask = (df['English'].str.len() <= 40)\r\n",
        "df = df.loc[mask]\r\n",
        "print(\"valid after: \", len(df))\r\n",
        "valid_df = df\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train before:  1000000\n",
            "train after:  576303\n",
            "test before:  2000\n",
            "test after:  914\n",
            "valid before:  2000\n",
            "valid after:  943\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2yqJd8dBGGx"
      },
      "source": [
        "import numpy as np\r\n",
        "np.random.seed(10)\r\n",
        "\r\n",
        "remove_n = int(len(train_df)/2)\r\n",
        "drop_indices = np.random.choice(train_df.index, remove_n, replace=False)\r\n",
        "train_df = train_df.drop(drop_indices)\r\n",
        "\r\n",
        "remove_n = int(len(test_df)/2)\r\n",
        "drop_indices = np.random.choice(test_df.index, remove_n, replace=False)\r\n",
        "test_df = test_df.drop(drop_indices)\r\n",
        "\r\n",
        "remove_n = int(len(valid_df)/2)\r\n",
        "drop_indices = np.random.choice(valid_df.index, remove_n, replace=False)\r\n",
        "valid_df = valid_df.drop(drop_indices)\r\n",
        "\r\n",
        "train_df, test_df, valid_df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QppedbGW89__"
      },
      "source": [
        "#import numpy as np\r\n",
        "#np.random.seed(10)\r\n",
        "\r\n",
        "#remove_n = int(len(train_df)/2)\r\n",
        "#drop_indices = np.random.choice(train_df.index, remove_n, replace=False)\r\n",
        "#train_df = train_df.drop(drop_indices)\r\n",
        "\r\n",
        "#remove_n = int(len(test_df)/2)\r\n",
        "#drop_indices = np.random.choice(test_df.index, remove_n, replace=False)\r\n",
        "#test_df = test_df.drop(drop_indices)\r\n",
        "\r\n",
        "#remove_n = int(len(valid_df)/2)\r\n",
        "#drop_indices = np.random.choice(valid_df.index, remove_n, replace=False)\r\n",
        "#valid_df = valid_df.drop(drop_indices)\r\n",
        "\r\n",
        "#train_df, test_df, valid_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJTQi9WQ4-i0"
      },
      "source": [
        "# Import Library\r\n",
        "import random\r\n",
        "import torch, torchtext\r\n",
        "from torchtext import data \r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "from torchtext.data import Field, BucketIterator\r\n",
        "import spacy\r\n",
        "import numpy as np\r\n",
        "import math\r\n",
        "import time\r\n",
        "\r\n",
        "\r\n",
        "#Then set a random seed for deterministic results/reproducability.\r\n",
        "SEED = 1234\r\n",
        "random.seed(SEED)\r\n",
        "np.random.seed(SEED)\r\n",
        "torch.manual_seed(SEED)\r\n",
        "torch.cuda.manual_seed(SEED)\r\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDKTeXzNColv",
        "outputId": "89eb9e49-4a74-445f-b10a-c6f331aff3a4"
      },
      "source": [
        "!python -m spacy download en\r\n",
        "!python -m spacy download es"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (51.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting es_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.2.5/es_core_news_sm-2.2.5.tar.gz (16.2MB)\n",
            "\u001b[K     |████████████████████████████████| 16.2MB 602kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from es_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (51.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.19.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.4.0)\n",
            "Building wheels for collected packages: es-core-news-sm\n",
            "  Building wheel for es-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for es-core-news-sm: filename=es_core_news_sm-2.2.5-cp36-none-any.whl size=16172935 sha256=c3b019f51ed71f5ff58a74e785003179774a04194a5fd9b6a8e16f77e29520a4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-uj74ydwn/wheels/05/4f/66/9d0c806f86de08e8645d67996798c49e1512f9c3a250d74242\n",
            "Successfully built es-core-news-sm\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/es_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/es\n",
            "You can now load the model via spacy.load('es')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRvrH2I6-0Qt"
      },
      "source": [
        "spacy_es = spacy.load('es')\r\n",
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtSzi2RhC_qT"
      },
      "source": [
        "def tokenize_es(text):\r\n",
        "    \"\"\"\r\n",
        "    Tokenizes Spanish text from a string into a list of strings\r\n",
        "    \"\"\"\r\n",
        "    return [tok.text for tok in spacy_es.tokenizer(text)]\r\n",
        "\r\n",
        "def tokenize_en(text):\r\n",
        "    \"\"\"\r\n",
        "    Tokenizes English text from a string into a list of strings\r\n",
        "    \"\"\"\r\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlc6SF3_C_h8"
      },
      "source": [
        "SRC = torchtext.data.Field(tokenize=tokenize_en, \r\n",
        "            init_token='<sos>', \r\n",
        "            eos_token='<eos>', \r\n",
        "            lower=True)\r\n",
        "\r\n",
        "TRG = torchtext.data.Field(tokenize = tokenize_es, \r\n",
        "            init_token='<sos>', \r\n",
        "            eos_token='<eos>', \r\n",
        "            lower=True)\r\n",
        "\r\n",
        "fields = [('English', SRC), ('Spanish', TRG)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQrWSvPI4-V2"
      },
      "source": [
        "from torchtext import data\r\n",
        "\r\n",
        "class DataFrameDataset(data.Dataset):\r\n",
        "\r\n",
        "    def __init__(self, df, text_field, label_field, is_test=False, **kwargs):\r\n",
        "        fields = [('text', text_field), ('label', label_field)]\r\n",
        "        examples = []\r\n",
        "        for i, row in df.iterrows():\r\n",
        "            label = row.Spanish if not is_test else None\r\n",
        "            text = row.English\r\n",
        "            examples.append(data.Example.fromlist([text, label], fields))\r\n",
        "\r\n",
        "        super().__init__(examples, fields, **kwargs)\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def sort_key(ex):\r\n",
        "        return len(ex.text)\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def splits(cls, text_field, label_field, train_df, val_df=None, test_df=None, **kwargs):\r\n",
        "        train_data, val_data, test_data = (None, None, None)\r\n",
        "\r\n",
        "        if train_df is not None:\r\n",
        "            train_data = cls(train_df.copy(), text_field, label_field, **kwargs)\r\n",
        "        if val_df is not None:\r\n",
        "            val_data = cls(val_df.copy(), text_field, label_field, **kwargs)\r\n",
        "        if test_df is not None:\r\n",
        "            test_data = cls(test_df.copy(), text_field, label_field, True, **kwargs)\r\n",
        "\r\n",
        "        return tuple(d for d in (train_data, val_data, test_data) if d is not None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3W4okgMLEbC"
      },
      "source": [
        "#train_df_2 = train_df[~train_df.applymap(lambda x: str.startswith(str(x), '--')).any(1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKdkmkZTOYqx"
      },
      "source": [
        "#train_df_3 = train_df[train_df.astype(str).str.startswith('--').any(1)]\r\n",
        "#train_df_3['English'] = train_df['English'].astype(str)\r\n",
        "#train_df_3['Spanish'] = train_df['Spanish'].astype(str)\r\n",
        "#train_df_3['English'] = pd.Series(train_df['English'], dtype=pd.StringDtype)\r\n",
        "#train_df_3['English'] = train_df_3[train_df_3['English'].str.startswith('--').any(1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg2ZgcjHMZaN"
      },
      "source": [
        "#train_df_3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcQJTYEUM6aT"
      },
      "source": [
        "#t_ds = DataFrameDataset.splits(text_field=SRC, label_field=TRG, train_df=train_df_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGnSsQvsWWUE"
      },
      "source": [
        "# create as type of test_df\r\n",
        "#test_df_3=test_df\r\n",
        "#test_df_3['English'] = test_df['English'].astype(str)\r\n",
        "#test_df_3['Spanish'] = test_df['Spanish'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbd5WCWxsgUO"
      },
      "source": [
        "#train_ds, val_ds, test_ds = DataFrameDataset.splits(text_field=SRC, label_field=TRG, train_df=train_df, val_df=valid_df, test_df=test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftNNvAuaXSkT"
      },
      "source": [
        "#test_example = [data.Example.fromlist([test_df.English.iloc[i],test_df.Spanish.iloc[i]], fields) for i in range(test_df.shape[0])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1jlz25CXmoq"
      },
      "source": [
        "#SampleDataset_test = data.Dataset(test_example, fields)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynm9D5MDXvJJ"
      },
      "source": [
        "#len(SampleDataset_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-cXlSooXmjk"
      },
      "source": [
        "#print(vars(SampleDataset_test.examples[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7VYyEtw4-QM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93a78752-3d93-428e-ce42-ae98f16a1f7d"
      },
      "source": [
        "train_df['English'] = train_df['English'].astype(str)\r\n",
        "train_df['Spanish'] = train_df['Spanish'].astype(str)\r\n",
        "valid_df['English'] = valid_df['English'].astype(str)\r\n",
        "valid_df['Spanish'] = valid_df['Spanish'].astype(str)\r\n",
        "test_df['English'] = test_df['English'].astype(str)\r\n",
        "test_df['Spanish'] = test_df['Spanish'].astype(str)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUWdxHd8_1ja"
      },
      "source": [
        "#df = test_df\r\n",
        "#print(df)\r\n",
        "#df['English'] = df['English'].astype('str')\r\n",
        "#mask = (df['English'].str.len() <= 20) & (df['Spanish'].str.len() <= 20)\r\n",
        "#mask = (df['English'].str.len() <= 50)\r\n",
        "#df = df.loc[mask]\r\n",
        "#len(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1NoGu4bY95v"
      },
      "source": [
        "train_example = [data.Example.fromlist([train_df.English.iloc[i],train_df.Spanish.iloc[i]], fields) for i in range(train_df.shape[0])]\r\n",
        "valid_example = [data.Example.fromlist([valid_df.English.iloc[i],valid_df.Spanish.iloc[i]], fields) for i in range(valid_df.shape[0])]\r\n",
        "test_example = [data.Example.fromlist([test_df.English.iloc[i],test_df.Spanish.iloc[i]], fields) for i in range(test_df.shape[0])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO9CNp44Y92p"
      },
      "source": [
        "OpusDataset_train = data.Dataset(train_example, fields)\r\n",
        "OpusDataset_dev = data.Dataset(test_example, fields)\r\n",
        "OpusDataset_valid = data.Dataset(valid_example, fields)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnzC04ICY9xg",
        "outputId": "594df6ae-502e-4d81-b695-62c8de9e08ac"
      },
      "source": [
        "(len(OpusDataset_train), len(OpusDataset_dev),len(OpusDataset_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(576303, 914, 943)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RFANLg0ZvOw"
      },
      "source": [
        "train_data = OpusDataset_train\r\n",
        "test_data = OpusDataset_dev\r\n",
        "valid_data = OpusDataset_valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygsyN63BZoPW"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq = 2)\r\n",
        "TRG.build_vocab(train_data, min_freq = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIIrvrd7ZoMc"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9WNqUJVZ4x2"
      },
      "source": [
        "BATCH_SIZE = 32\r\n",
        "\r\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\r\n",
        "    (train_data, valid_data, test_data), \r\n",
        "    batch_size = BATCH_SIZE,\r\n",
        "    sort_key=lambda x : len(x.English),\r\n",
        "    sort_within_batch=False, \r\n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m8uqfmkZ4vM"
      },
      "source": [
        "class Encoder(nn.Module):\r\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, dropout):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.hid_dim = hid_dim\r\n",
        "        \r\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim) #no dropout as only one layer!\r\n",
        "        \r\n",
        "        self.rnn = nn.GRU(emb_dim, hid_dim)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, src):\r\n",
        "        \r\n",
        "        #src = [src len, batch size]\r\n",
        "        \r\n",
        "        embedded = self.dropout(self.embedding(src))\r\n",
        "        \r\n",
        "        #embedded = [src len, batch size, emb dim]\r\n",
        "        \r\n",
        "        outputs, hidden = self.rnn(embedded) #no cell state!\r\n",
        "        \r\n",
        "        #outputs = [src len, batch size, hid dim * n directions]\r\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\r\n",
        "        \r\n",
        "        #outputs are always from the top hidden layer\r\n",
        "        \r\n",
        "        return hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipRDDCKCZ4sX"
      },
      "source": [
        "class Decoder(nn.Module):\r\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, dropout):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.hid_dim = hid_dim\r\n",
        "        self.output_dim = output_dim\r\n",
        "        \r\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\r\n",
        "        \r\n",
        "        self.rnn = nn.GRU(emb_dim + hid_dim, hid_dim)\r\n",
        "        \r\n",
        "        self.fc_out = nn.Linear(emb_dim + hid_dim * 2, output_dim)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, input, hidden, context):\r\n",
        "        \r\n",
        "        #input = [batch size]\r\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\r\n",
        "        #context = [n layers * n directions, batch size, hid dim]\r\n",
        "        \r\n",
        "        #n layers and n directions in the decoder will both always be 1, therefore:\r\n",
        "        #hidden = [1, batch size, hid dim]\r\n",
        "        #context = [1, batch size, hid dim]\r\n",
        "        \r\n",
        "        input = input.unsqueeze(0)\r\n",
        "        \r\n",
        "        #input = [1, batch size]\r\n",
        "        \r\n",
        "        embedded = self.dropout(self.embedding(input))\r\n",
        "        \r\n",
        "        #embedded = [1, batch size, emb dim]\r\n",
        "                \r\n",
        "        emb_con = torch.cat((embedded, context), dim = 2)\r\n",
        "            \r\n",
        "        #emb_con = [1, batch size, emb dim + hid dim]\r\n",
        "            \r\n",
        "        output, hidden = self.rnn(emb_con, hidden)\r\n",
        "        \r\n",
        "        #output = [seq len, batch size, hid dim * n directions]\r\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\r\n",
        "        \r\n",
        "        #seq len, n layers and n directions will always be 1 in the decoder, therefore:\r\n",
        "        #output = [1, batch size, hid dim]\r\n",
        "        #hidden = [1, batch size, hid dim]\r\n",
        "        \r\n",
        "        output = torch.cat((embedded.squeeze(0), hidden.squeeze(0), context.squeeze(0)), \r\n",
        "                           dim = 1)\r\n",
        "        \r\n",
        "        #output = [batch size, emb dim + hid dim * 2]\r\n",
        "        \r\n",
        "        prediction = self.fc_out(output)\r\n",
        "        \r\n",
        "        #prediction = [batch size, output dim]\r\n",
        "        \r\n",
        "        return prediction, hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfOkQTBUZoJy"
      },
      "source": [
        "class Seq2Seq(nn.Module):\r\n",
        "    def __init__(self, encoder, decoder, device):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.encoder = encoder\r\n",
        "        self.decoder = decoder\r\n",
        "        self.device = device\r\n",
        "        \r\n",
        "        assert encoder.hid_dim == decoder.hid_dim, \\\r\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\r\n",
        "        \r\n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\r\n",
        "        \r\n",
        "        #src = [src len, batch size]\r\n",
        "        #trg = [trg len, batch size]\r\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\r\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\r\n",
        "        \r\n",
        "        batch_size = trg.shape[1]\r\n",
        "        trg_len = trg.shape[0]\r\n",
        "        trg_vocab_size = self.decoder.output_dim\r\n",
        "        \r\n",
        "        #tensor to store decoder outputs\r\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\r\n",
        "        \r\n",
        "        #last hidden state of the encoder is the context\r\n",
        "        context = self.encoder(src)\r\n",
        "        \r\n",
        "        #context also used as the initial hidden state of the decoder\r\n",
        "        hidden = context\r\n",
        "        \r\n",
        "        #first input to the decoder is the <sos> tokens\r\n",
        "        input = trg[0,:]\r\n",
        "        \r\n",
        "        for t in range(1, trg_len):\r\n",
        "            \r\n",
        "            #insert input token embedding, previous hidden state and the context state\r\n",
        "            #receive output tensor (predictions) and new hidden state\r\n",
        "            output, hidden = self.decoder(input, hidden, context)\r\n",
        "            \r\n",
        "            #place predictions in a tensor holding predictions for each token\r\n",
        "            outputs[t] = output\r\n",
        "            \r\n",
        "            #decide if we are going to use teacher forcing or not\r\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\r\n",
        "            \r\n",
        "            #get the highest predicted token from our predictions\r\n",
        "            top1 = output.argmax(1) \r\n",
        "            \r\n",
        "            #if teacher forcing, use actual next token as next input\r\n",
        "            #if not, use predicted token\r\n",
        "            input = trg[t] if teacher_force else top1\r\n",
        "\r\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFlNcPVwrwoo"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\r\n",
        "OUTPUT_DIM = len(TRG.vocab)\r\n",
        "#ENC_EMB_DIM = 256\r\n",
        "ENC_EMB_DIM = 128\r\n",
        "#DEC_EMB_DIM = 256\r\n",
        "DEC_EMB_DIM = 128\r\n",
        "HID_DIM = 256\r\n",
        "#HID_DIM = 512\r\n",
        "ENC_DROPOUT = 0.5\r\n",
        "DEC_DROPOUT = 0.5\r\n",
        "\r\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, ENC_DROPOUT)\r\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, DEC_DROPOUT)\r\n",
        "\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "\r\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDli6Hd_rwk-",
        "outputId": "7e347a4b-c027-450d-a161-d605e2cec773"
      },
      "source": [
        "def init_weights(m):\r\n",
        "    for name, param in m.named_parameters():\r\n",
        "        nn.init.normal_(param.data, mean=0, std=0.01)\r\n",
        "        \r\n",
        "model.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(32384, 128)\n",
              "    (rnn): GRU(128, 256)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(44916, 128)\n",
              "    (rnn): GRU(384, 256)\n",
              "    (fc_out): Linear(in_features=640, out_features=44916, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvtYFW8krwh4",
        "outputId": "f36f001a-7fc7-47bd-ac1b-c3e33cc541cd"
      },
      "source": [
        "def count_parameters(model):\r\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "\r\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 39,475,060 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUZCEPlSrwfA"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yft3_2Xqrwcu"
      },
      "source": [
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeTMkHVlrwZZ"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\r\n",
        "    \r\n",
        "    model.train()\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    \r\n",
        "    for i, batch in enumerate(iterator):\r\n",
        "        \r\n",
        "        src = batch.English\r\n",
        "        trg = batch.Spanish\r\n",
        "        \r\n",
        "        optimizer.zero_grad()\r\n",
        "        \r\n",
        "        output = model(src, trg)\r\n",
        "        \r\n",
        "        #trg = [trg len, batch size]\r\n",
        "        #output = [trg len, batch size, output dim]\r\n",
        "        \r\n",
        "        output_dim = output.shape[-1]\r\n",
        "        \r\n",
        "        output = output[1:].view(-1, output_dim)\r\n",
        "        trg = trg[1:].view(-1)\r\n",
        "        \r\n",
        "        #trg = [(trg len - 1) * batch size]\r\n",
        "        #output = [(trg len - 1) * batch size, output dim]\r\n",
        "        \r\n",
        "        loss = criterion(output, trg)\r\n",
        "        \r\n",
        "        loss.backward()\r\n",
        "        \r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\r\n",
        "        \r\n",
        "        optimizer.step()\r\n",
        "        \r\n",
        "        epoch_loss += loss.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am6bMBE6rwXj"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\r\n",
        "    \r\n",
        "    model.eval()\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "    \r\n",
        "        for i, batch in enumerate(iterator):\r\n",
        "\r\n",
        "            src = batch.English\r\n",
        "            trg = batch.Spanish\r\n",
        "\r\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\r\n",
        "\r\n",
        "            #trg = [trg len, batch size]\r\n",
        "            #output = [trg len, batch size, output dim]\r\n",
        "\r\n",
        "            output_dim = output.shape[-1]\r\n",
        "            \r\n",
        "            output = output[1:].view(-1, output_dim)\r\n",
        "            trg = trg[1:].view(-1)\r\n",
        "\r\n",
        "            #trg = [(trg len - 1) * batch size]\r\n",
        "            #output = [(trg len - 1) * batch size, output dim]\r\n",
        "\r\n",
        "            loss = criterion(output, trg)\r\n",
        "\r\n",
        "            epoch_loss += loss.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63yI5uV4rwWK"
      },
      "source": [
        "def epoch_time(start_time, end_time):\r\n",
        "    elapsed_time = end_time - start_time\r\n",
        "    elapsed_mins = int(elapsed_time / 60)\r\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\r\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMkPRSwvrwRQ",
        "outputId": "5c300f8a-ccab-4b85-fffa-801bdaefc1ef"
      },
      "source": [
        "N_EPOCHS = 10\r\n",
        "CLIP = 1\r\n",
        "\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "for epoch in range(N_EPOCHS):\r\n",
        "    \r\n",
        "    start_time = time.time()\r\n",
        "    \r\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\r\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\r\n",
        "    \r\n",
        "    end_time = time.time()\r\n",
        "    \r\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\r\n",
        "    \r\n",
        "    if valid_loss < best_valid_loss:\r\n",
        "        best_valid_loss = valid_loss\r\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\r\n",
        "    \r\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\r\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\r\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 36m 5s\n",
            "\tTrain Loss: 3.820 | Train PPL:  45.614\n",
            "\t Val. Loss: 3.895 |  Val. PPL:  49.165\n",
            "Epoch: 02 | Time: 36m 6s\n",
            "\tTrain Loss: 3.041 | Train PPL:  20.935\n",
            "\t Val. Loss: 3.733 |  Val. PPL:  41.787\n",
            "Epoch: 03 | Time: 36m 8s\n",
            "\tTrain Loss: 2.821 | Train PPL:  16.796\n",
            "\t Val. Loss: 3.645 |  Val. PPL:  38.276\n",
            "Epoch: 04 | Time: 36m 12s\n",
            "\tTrain Loss: 2.700 | Train PPL:  14.879\n",
            "\t Val. Loss: 3.649 |  Val. PPL:  38.427\n",
            "Epoch: 05 | Time: 36m 18s\n",
            "\tTrain Loss: 2.621 | Train PPL:  13.743\n",
            "\t Val. Loss: 3.636 |  Val. PPL:  37.941\n",
            "Epoch: 06 | Time: 36m 12s\n",
            "\tTrain Loss: 2.560 | Train PPL:  12.940\n",
            "\t Val. Loss: 3.631 |  Val. PPL:  37.735\n",
            "Epoch: 07 | Time: 36m 18s\n",
            "\tTrain Loss: 2.515 | Train PPL:  12.370\n",
            "\t Val. Loss: 3.601 |  Val. PPL:  36.640\n",
            "Epoch: 08 | Time: 36m 16s\n",
            "\tTrain Loss: 2.483 | Train PPL:  11.976\n",
            "\t Val. Loss: 3.598 |  Val. PPL:  36.520\n",
            "Epoch: 09 | Time: 36m 15s\n",
            "\tTrain Loss: 2.453 | Train PPL:  11.621\n",
            "\t Val. Loss: 3.610 |  Val. PPL:  36.959\n",
            "Epoch: 10 | Time: 36m 18s\n",
            "\tTrain Loss: 2.425 | Train PPL:  11.304\n",
            "\t Val. Loss: 3.635 |  Val. PPL:  37.901\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qDLZzDorwOL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8647005b-b691-4894-ee6b-097db17af852"
      },
      "source": [
        "model.load_state_dict(torch.load('tut2-model.pt'))\r\n",
        "\r\n",
        "test_loss = evaluate(model, test_iterator, criterion)\r\n",
        "\r\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 3.651 | Test PPL:  38.525 |\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}